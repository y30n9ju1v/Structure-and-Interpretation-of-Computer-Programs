이 글은 `프로시저`라는 걸 배우고 그걸 어떻게 잘 사용하는지 알려주는 글이야. 우리가 이제 기본적인 계산하는 방법은 알았는데, 이걸로 어떻게 프로그램을 잘 짤지는 아직 모른다는 얘기지. 마치 체스 두는 법은 알지만, 어떻게 이길지는 모르는 초보자와 같대.

프로그램을 잘 만들려면, 네가 짜는 코드들이 컴퓨터 안에서 어떻게 움직이고 어떤 결과를 낼지 미리 상상할 수 있어야 해. 사진작가가 사진을 찍기 전에 빛이나 노출을 미리 생각하는 것처럼 말이야. 프로그래밍에서도 마찬가지로, 우리가 짠 코드가 어떤 `과정(process)`을 만들어낼지 상상하는 능력이 중요하대. 그래야 원하는 대로 작동하는 프로그램을 만들 수 있거든.

`프로시저`는 계산 과정이 `지역적으로` 어떻게 발전하는지에 대한 패턴이야. 각 단계가 이전 단계를 바탕으로 어떻게 만들어지는지 정해주는 거지. 우리는 프로시저가 정해준 지역적인 발전으로 인해 전체적인 과정이 어떻게 되는지 알아보고 싶어. 이걸 일반화하는 건 아주 어렵지만, 몇 가지 대표적인 과정의 형태는 설명할 수 있대.

이 섹션에서는 간단한 프로시저들이 만들어내는 과정들의 흔한 `모양`들을 살펴볼 거야. 그리고 이 과정들이 `시간`과 `공간`이라는 중요한 컴퓨터 자원을 얼마나 많이 사용하는지도 알아볼 거지. 우리가 다룰 프로시저들은 아주 간단한 예시들이야. 마치 사진에서 테스트 패턴처럼, 실용적인 예시라기보다는 단순화된 원형적인 패턴이라고 생각하면 돼.

### 1.2.1 선형 재귀와 반복 (Linear Recursion and Iteration)

먼저 `계승 함수`부터 볼까? $n!\, = \,{n \cdot (n - 1)} \cdot {(n - 2)}\cdots{3 \cdot 2 \cdot 1.}$ 이렇게 정의돼. 계승을 계산하는 방법은 여러 가지가 있는데, 그중 하나는 $n!$이 어떤 양의 정수 n에 대해 n 곱하기 $(n-1)!$과 같다는 걸 이용하는 거야. 즉, $n!\, = \,{n \cdot \lbrack(n - 1)} \cdot {(n - 2)}\cdots{3 \cdot 2 \cdot 1\rbrack}\, = \,{n \cdot (n - 1)!.}$ 이지. 그래서 $(n-1)!$을 계산하고 그 결과에 n을 곱해서 $n!$을 계산할 수 있어. 만약 $1!$이 1과 같다고 추가하면, 이 관찰은 바로 프로시저로 바꿀 수 있어.

Code snippet

```
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
```

우리는 1.1.5에서 배웠던 `대치 모델`을 사용해서 이 프로시저가 6!을 계산하는 모습을 그림 1.3에서 볼 수 있어.

![](./images/ch1-Z-G-7.gif)

자, 이제 계승을 계산하는 다른 방식을 생각해 보자. $n!$을 계산하는 규칙을 이렇게 설명할 수 있어. 먼저 1에 2를 곱하고, 그 결과에 3을 곱하고, 다시 4를 곱하고, 이렇게 n에 도달할 때까지 계속하는 거지. 좀 더 정식으로 말하면, 현재 곱해진 값(product)을 유지하면서 1부터 n까지 세는 카운터(counter)를 같이 가져가는 거야. 계산 과정을 이렇게 설명할 수 있어. 카운터와 곱해진 값이 다음 단계로 갈 때마다 다음 규칙에 따라 동시에 변하는 거지.

Code snippet

```
product
  ←
 counter * product
counter
  ←
 counter + 1
```

그리고 카운터가 n을 초과했을 때 곱해진 값(product)이 $n!$의 값이라고 정하는 거야.

다시 한번, 이 설명을 계승을 계산하는 프로시저로 바꿀 수 있어.

Code snippet

```
(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
```

이전처럼, 대치 모델을 사용해서 6!을 계산하는 과정을 시각화할 수 있어. 그림 1.4를 봐봐.

![](./images/ch1-Z-G-10.gif)

두 과정을 비교해 봐. 어떤 관점에서 보면 전혀 다르지 않은 것 같아. 둘 다 같은 범위에서 같은 수학 함수를 계산하고, 각각 $n!$을 계산하는 데 n에 비례하는 단계가 필요해. 사실, 두 과정 모두 같은 순서의 곱셈을 수행하고, 같은 중간 결과들을 얻지. 하지만 두 과정의 `모양`을 보면, 완전히 다르게 진화하고 있어.

첫 번째 과정을 살펴보자. 대치 모델은 확장되었다가 수축하는 형태를 보여줘. 그림 1.3의 화살표로 표시되어 있지. 확장은 과정이 `지연된 연산`의 사슬(이 경우 곱셈의 사슬)을 구축하면서 발생하고, 수축은 실제로 연산이 수행될 때 발생해. 이런 종류의 과정, 즉 지연된 연산의 사슬로 특징지어지는 과정을 `재귀 과정(recursive process)`이라고 불러. 이 과정을 수행하려면 인터프리터가 나중에 수행할 연산들을 계속 추적해야 해. $n!$을 계산할 때, 지연된 곱셈 사슬의 길이, 따라서 그것을 추적하는 데 필요한 정보의 양은 n에 선형적으로 비례하며( n에 비례함), 단계 수와 같아. 이런 과정을 `선형 재귀 과정(linear recursive process)`이라고 해.

반대로, 두 번째 과정은 성장하거나 축소되지 않아. 각 단계에서 어떤 n에 대해서든 우리가 추적해야 할 것은 변수 `product`, `counter`, `max-count`의 현재 값뿐이야. 우리는 이것을 `반복 과정(iterative process)`이라고 불러. 일반적으로 반복 과정은 고정된 수의 `상태 변수`와, 과정이 상태에서 상태로 이동할 때 상태 변수가 어떻게 업데이트되어야 하는지를 설명하는 고정된 규칙, 그리고 (선택 사항인) 과정이 종료되어야 하는 조건을 지정하는 종료 테스트로 그 상태를 요약할 수 있는 과정이야. $n!$을 계산할 때, 필요한 단계 수는 n에 선형적으로 비례해. 이런 과정을 `선형 반복 과정(linear iterative process)`이라고 해.

두 과정의 차이는 다른 방식으로도 볼 수 있어. 반복 과정의 경우, 프로그램 변수들이 어떤 시점에서든 과정의 상태를 완벽하게 설명해줘. 만약 우리가 중간에 계산을 멈췄다면, 계산을 재개하기 위해 인터프리터에 세 가지 프로그램 변수의 값만 제공하면 돼. 하지만 재귀 과정은 그렇지 않아. 이 경우, 인터프리터가 유지하고 프로그램 변수에 포함되지 않은 추가적인 `숨겨진` 정보가 있어. 이것은 지연된 연산의 사슬을 처리하는 데 `과정이 어디에 있는지`를 나타내. 사슬이 길어질수록 더 많은 정보를 유지해야 하지.

반복과 재귀를 대조할 때, `재귀 과정`의 개념과 `재귀 프로시저`의 개념을 혼동하지 않도록 조심해야 해. 프로시저를 재귀적이라고 설명할 때는 프로시저 정의가 (직접적으로든 간접적으로든) 프로시저 자체를 참조한다는 구문적인 사실을 말하는 거야. 하지만 과정을 선형 재귀적이라고 설명할 때는 과정이 어떻게 진화하는지에 대해 말하는 것이지, 프로시저가 어떻게 작성되는지의 구문에 대해 말하는 것이 아니야. `fact-iter`와 같은 재귀 프로시저가 반복 과정을 생성한다고 말하는 것이 혼란스러울 수도 있어. 하지만 이 과정은 정말로 반복적이야. 세 개의 상태 변수로 상태가 완전히 포착되고, 인터프리터는 과정을 실행하기 위해 세 개의 변수만 추적하면 되거든.

과정과 프로시저의 구별이 혼란스러울 수 있는 한 가지 이유는 대부분의 일반적인 언어 구현(Ada, Pascal, C 포함)이 어떤 재귀 프로시저의 해석도 프로시저 호출 횟수에 따라 메모리 양이 증가하도록 설계되어 있다는 점이야. 심지어 원칙적으로 반복적인 과정일 때도 말이지. 결과적으로, 이 언어들은 `do`, `repeat`, `until`, `for`, `while`과 같은 특별한 목적의 `반복 구조`에 의존해야만 반복 과정을 설명할 수 있어. 5장에서 살펴볼 Scheme 구현은 이러한 결함을 가지고 있지 않아. 반복 과정이 재귀 프로시저로 설명되더라도 일정한 공간에서 반복 과정을 실행할 거야. 이러한 속성을 가진 구현을 `꼬리 재귀(tail-recursive)`라고 해. 꼬리 재귀 구현을 사용하면 일반적인 프로시저 호출 메커니즘을 사용하여 반복을 표현할 수 있어. 따라서 특별한 반복 구조는 단지 `구문적 설탕(syntactic sugar)`으로만 유용하게 쓰일 뿐이지.

**연습문제 1.9:** 다음 두 프로시저는 각각 인자를 1씩 증가시키는 `inc` 프로시저와 인자를 1씩 감소시키는 `dec` 프로시저를 사용하여 두 양의 정수를 더하는 방법을 정의해.

Code snippet

```
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
```

대치 모델을 사용하여 `(+ 4 5)`를 평가할 때 각 프로시저가 생성하는 과정을 설명해봐. 이 과정들은 반복적일까 아니면 재귀적일까?

**연습문제 1.10:** 다음 프로시저는 아커만 함수(Ackermann’s function)라는 수학 함수를 계산해.

Code snippet

```
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
```

다음 표현식들의 값은 무엇일까?

Code snippet

```
(A 1 10)
(A 2 4)
(A 3 3)
```

위에서 정의된 `A` 프로시저를 사용하는 다음 프로시저들을 고려해봐:

Code snippet

```
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
```

양의 정수 n 값에 대해 프로시저 `f`, `g`, `h`가 계산하는 함수에 대한 간결한 수학적 정의를 제공해봐. 예를 들어, `(k n)`은 5n2를 계산해.

### 1.2.2 트리 재귀 (Tree Recursion)

계산의 또 다른 흔한 패턴을 `트리 재귀(tree recursion)`라고 해. 예를 들어, 피보나치 수열을 계산하는 걸 생각해 보자. 피보나치 수열은 각 숫자가 앞의 두 숫자의 합인 수열이야.

0, 1, 1, 2, 3, 5, 8, 13, 21, ….

일반적으로 피보나치 수는 다음 규칙으로 정의할 수 있어.

$$\text{Fib}(n)\; = \;\begin{cases}
0 & {\;\text{if}\;\; n = 0,} \\
1 & {\;\text{if}\;\; n = 1,} \\
{\text{Fib}(n - 1) + \text{Fib}(n - 2)} & {\;\text{otherwise}.} \\
\end{cases}$$

이 정의를 피보나치 수를 계산하는 재귀 프로시저로 바로 바꿀 수 있어.

Code snippet

```
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
```

이 계산의 패턴을 살펴보자. `(fib 5)`를 계산하려면 `(fib 4)`와 `(fib 3)`을 계산해야 해. `(fib 4)`를 계산하려면 `(fib 3)`와 `(fib 2)`를 계산해야 하고. 일반적으로, 이 과정은 그림 1.5처럼 트리 모양을 띠게 돼. (맨 아래를 제외하고) 각 레벨에서 가지가 두 개로 갈라지는 것에 주목해. 이것은 `fib` 프로시저가 호출될 때마다 자신을 두 번 호출한다는 사실을 반영하는 거야.

![](./images/ch1-Z-G-13.gif)

이 프로시저는 전형적인 트리 재귀를 보여주는 예시로는 좋지만, 너무 많은 중복 계산을 하기 때문에 피보나치 수를 계산하는 데는 끔찍한 방법이야. 그림 1.5를 보면 `(fib 3)` 전체 계산(거의 절반의 작업)이 중복되는 것을 알 수 있어. 사실, 프로시저가 `(fib 1)` 또는 `(fib 0)`을 계산하는 횟수(일반적으로 위 트리의 잎 노드 수)가 정확히 $\text{Fib}(n + 1)$임을 보여주는 것은 어렵지 않아. 이게 얼마나 안 좋은지 감을 잡으려면, $\text{Fib}(n)$의 값이 n에 따라 기하급수적으로 증가한다는 것을 알 수 있어. 더 정확히 말하면 (1.13번 연습문제 참조), $\text{Fib}(n)$은 $\varphi^{n}/\sqrt{5}$에 가장 가까운 정수인데, 여기서 $\varphi\, = \,\frac{1 + \sqrt{5}}{2}\, \approx \, 1.6180$는 `황금 비율`이며 $\varphi^{2}\, = \,{\varphi + 1.}$ 방정식을 만족해. 따라서 이 과정은 입력에 따라 단계 수가 기하급수적으로 증가해. 반면에 필요한 공간은 입력에 따라 선형적으로만 증가하는데, 계산 중 어떤 시점에서든 트리에서 우리 위에 있는 노드들만 추적하면 되기 때문이야. 일반적으로 트리 재귀 과정에 필요한 단계 수는 트리의 노드 수에 비례하고, 필요한 공간은 트리의 최대 깊이에 비례해.

우리는 피보나치 수를 계산하는 반복 과정을 만들 수도 있어. 아이디어는 정수 쌍 a와 b를 사용하는 건데, `Fib(1) = 1`과 `Fib(0) = 0`으로 초기화하고, 다음 변환을 반복적으로 적용하는 거야.

$$\begin{array}{l}
{a\;\leftarrow\; a + b,} \\
{b\;\leftarrow\; a.} \\
\end{array}$$

이 변환을 n번 적용하면, a와 b가 각각 `Fib(n + 1)`과 `Fib(n)`과 같아진다는 것을 보여주는 것은 어렵지 않아. 따라서 다음 프로시저를 사용하여 피보나치 수를 반복적으로 계산할 수 있어.

Code snippet

```
(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
```

`Fib(n)`을 계산하는 이 두 번째 방법은 선형 반복이야. 두 방법이 필요한 단계 수의 차이(하나는 n에 선형적이고, 다른 하나는 `Fib(n)` 자체만큼 빠르게 증가함)는 입력이 작을 때도 엄청나게 커.

이것 때문에 트리 재귀 과정이 쓸모없다고 결론 내려서는 안 돼. 숫자보다는 계층적으로 구조화된 데이터를 다루는 과정을 고려할 때, 트리 재귀가 자연스럽고 강력한 도구라는 것을 알게 될 거야. 하지만 수치 연산에서도 트리 재귀 과정은 프로그램을 이해하고 설계하는 데 유용할 수 있어. 예를 들어, 첫 번째 `fib` 프로시저는 두 번째 프로시저보다 훨씬 덜 효율적이지만, 피보나치 수열의 정의를 Lisp으로 번역한 것과 거의 같아서 더 직관적이야. 반복 알고리즘을 만들려면 계산을 세 가지 상태 변수를 가진 반복으로 재구성할 수 있다는 점을 알아채야 했거든.

#### 예시: 거스름돈 세기 (Example: Counting change)

반복 피보나치 알고리즘을 생각해내는 데는 약간의 영리함만 있으면 돼. 이와 대조적으로 다음 문제를 생각해 보자. 50센트, 25센트, 10센트, 5센트, 1센트 동전이 주어졌을 때, 1달러를 거스름돈으로 줄 수 있는 방법은 몇 가지나 될까? 더 일반적으로, 주어진 금액에 대해 거스름돈을 줄 수 있는 방법의 수를 계산하는 프로시저를 작성할 수 있을까?

이 문제는 재귀 프로시저로 간단한 해결책을 가지고 있어. 사용 가능한 동전 종류를 어떤 순서로 배열되어 있다고 생각해 보자. 그러면 다음 관계가 성립해:

n가지 종류의 동전을 사용하여 금액 a를 거스름돈으로 줄 수 있는 방법의 수는 다음을 더한 것과 같아.

- 첫 번째 종류의 동전을 제외한 모든 동전 종류를 사용하여 금액 a를 거스름돈으로 줄 수 있는 방법의 수, 더하기
    
- n가지 종류의 동전을 모두 사용하여 금액 a−d를 거스름돈으로 줄 수 있는 방법의 수. 여기서 d는 첫 번째 종류 동전의 액면가야.
    

이것이 왜 사실인지 알아보려면, 거스름돈을 만드는 방법은 두 그룹으로 나눌 수 있다는 점을 살펴보자. 첫 번째 종류의 동전을 전혀 사용하지 않는 경우와 사용하는 경우야. 따라서 어떤 금액에 대한 거스름돈을 만드는 총 방법의 수는 첫 번째 종류의 동전을 사용하지 않고 금액에 대한 거스름돈을 만드는 방법의 수와, 첫 번째 종류의 동전을 사용한다고 가정하고 거스름돈을 만드는 방법의 수를 더한 것과 같아. 하지만 후자의 수는 첫 번째 종류의 동전을 사용한 후에 남은 금액에 대한 거스름돈을 만드는 방법의 수와 같아.

따라서, 주어진 금액을 거스름돈으로 줄 문제를 더 작은 금액을 더 적은 종류의 동전을 사용하여 거스름돈으로 줄 문제로 재귀적으로 줄일 수 있어. 이 축소 규칙을 신중하게 고려하고, 다음 퇴화된 경우를 지정하면 이 규칙을 알고리즘을 설명하는 데 사용할 수 있다는 것을 스스로 납득해봐.

- 만약 a가 정확히 0이면, 1가지 방법으로 세야 해.
    
- 만약 a가 0보다 작으면, 0가지 방법으로 세야 해.
    
- 만약 n이 0이면, 0가지 방법으로 세야 해.
    

이 설명을 재귀 프로시저로 쉽게 바꿀 수 있어.

Code snippet

```
(define (count-change amount)
  (cc amount 5))

(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0)
             (= kinds-of-coins 0))
         0)
        (else
         (+ (cc amount (- kinds-of-coins 1))
            (cc (- amount (first-denomination
                           kinds-of-coins))
                kinds-of-coins)))))

(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
```

(`first-denomination` 프로시저는 사용 가능한 동전 종류의 수를 입력으로 받아서 첫 번째 종류의 동전 액면가를 반환해. 여기서 우리는 동전을 가장 큰 것부터 가장 작은 것 순서로 배열되어 있다고 생각하지만, 어떤 순서도 괜찮아.) 이제 1달러 거스름돈에 대한 원래 질문에 답할 수 있어.

Code snippet

```
(count-change 100)
292
```

`count-change`는 첫 번째 `fib` 구현과 비슷한 중복을 가진 트리 재귀 과정을 생성해. (292가 계산되는 데 꽤 오랜 시간이 걸릴 거야.) 반면에, 결과를 계산하기 위한 더 나은 알고리즘을 설계하는 것은 명확하지 않고, 이 문제는 숙제로 남겨둘게. 트리 재귀 과정이 매우 비효율적일 수 있지만, 종종 지정하고 이해하기 쉽다는 점 때문에 사람들이 동일한 결과를 계산하는 더 효율적인 프로시저로 트리 재귀 프로시저를 변환할 수 있는 `스마트 컴파일러`를 설계해야 한다고 제안했어.

**연습문제 1.11:** 함수 $f(n) = n$ if $n < 3$ 일 때 ${f(n)} = {f(n - 1)} + {2f(n - 2)} + {3f(n - 3)}$ if $n \geq 3$ 이라는 규칙으로 정의돼. 재귀 과정을 통해 f를 계산하는 프로시저를 작성해봐. 반복 과정을 통해 f를 계산하는 프로시저를 작성해봐.

**연습문제 1.12:** 다음 숫자 패턴을 `파스칼의 삼각형(Pascal’s triangle)`이라고 해.

Code snippet

```
         1
       1   1
     1   2   1
   1   3   3   1
 1   4   6   4   1
       . . .
```

삼각형의 가장자리에 있는 숫자들은 모두 1이고, 삼각형 안의 각 숫자는 그 위 두 숫자의 합이야. 재귀 과정을 통해 파스칼의 삼각형 요소를 계산하는 프로시저를 작성해봐.

**연습문제 1.13:** $\text{Fib}(n)$이 $\varphi^{n}/\sqrt{5}$에 가장 가까운 정수임을 증명해봐. 여기서 $\varphi = {(1 + \sqrt{5})/2}$야. 힌트: $\psi = {(1 - \sqrt{5})/2}$라고 해봐. 귀납법과 피보나치 수의 정의(1.2.2 참조)를 사용하여 ${\text{Fib}(n)} = {(\varphi^{n} - \psi^{n})/\sqrt{5}}$임을 증명해.

### 1.2.3 성장의 차수 (Orders of Growth)

이전 예시들은 과정들이 컴퓨터 자원을 소비하는 속도가 상당히 다를 수 있다는 것을 보여줘. 이런 차이를 설명하는 편리한 방법 중 하나는 입력이 커질수록 과정이 요구하는 자원의 `대략적인` 양을 나타내는 `성장의 차수(order of growth)` 개념을 사용하는 거야.

n을 문제의 크기를 측정하는 매개변수라고 하고, $R(n)$을 크기 n의 문제에 대해 과정이 요구하는 자원의 양이라고 하자. 이전 예시들에서는 n을 주어진 함수를 계산해야 할 숫자로 생각했지만, 다른 가능성도 있어. 예를 들어, 숫자의 제곱근에 대한 근사치를 계산하는 것이 목표라면, n을 필요한 자릿수 정확도로 볼 수 있어. 행렬 곱셈의 경우 n을 행렬의 행 수로 볼 수 있지. 일반적으로 주어진 과정을 분석하고 싶은 문제의 여러 속성이 있어. 비슷하게, $R(n)$은 사용되는 내부 저장 레지스터의 수, 수행되는 기본 기계 연산의 수 등을 측정할 수 있어. 한 번에 고정된 수의 연산만 수행하는 컴퓨터에서는 필요한 시간이 수행된 기본 기계 연산의 수에 비례할 거야.

우리는 $R(n)$이 충분히 큰 n 값에 대해 n과 독립적인 양의 상수 $k_{1}$과 $k_{2}$가 존재하여 ${k_1f(n)} \leq {R(n)} \leq {k_2f(n)}$를 만족할 때, $R(n)$이 성장 차수 $\Theta(f(n))$를 갖는다고 말해. (즉, 큰 n에 대해 R(n) 값은 $k_1f(n)$와 $k_{2}f(n)$ 사이에 끼어 있다는 뜻이야.)

예를 들어, 1.2.1에서 설명된 계승을 계산하는 선형 재귀 과정에서 단계 수는 입력 n에 비례하여 증가해. 따라서 이 과정에 필요한 단계 수는 $\Theta(n)$으로 증가해. 우리는 또한 필요한 공간도 $\Theta(n)$으로 증가한다는 것을 보았지. 반복 계승의 경우, 단계 수는 여전히 $\Theta(n)$이지만 공간은 $\Theta(1)$—즉, 상수야. 트리 재귀 피보나치 계산은 $\Theta(\varphi^{n})$ 단계와 $\Theta(n)$ 공간을 요구하는데, 여기서 $\varphi$는 1.2.2에서 설명된 황금 비율이야.

성장의 차수는 과정의 동작에 대한 대략적인 설명만을 제공해. 예를 들어, $n^{2}$ 단계가 필요한 과정, $1000n^{2}$ 단계가 필요한 과정, 그리고 ${3n^{2}} + {10n} + 17$ 단계가 필요한 과정은 모두 $\Theta(n^2)$의 성장 차수를 가져. 반면에, 성장의 차수는 문제의 크기를 변경함에 따라 과정의 동작이 어떻게 변할 것으로 예상할 수 있는지 유용한 지표를 제공해. $\Theta(n)$ (선형) 과정의 경우, 크기를 두 배로 늘리면 사용되는 자원의 양도 대략 두 배가 될 거야. 지수 과정의 경우, 문제 크기가 한 번 증가할 때마다 자원 사용량은 상수 인자만큼 곱해질 거야. 1.2의 나머지 부분에서는 성장 차수가 로그형인 두 가지 알고리즘을 살펴볼 건데, 문제 크기를 두 배로 늘리면 자원 요구 사항이 상수량만큼 증가한다는 의미야.

**연습문제 1.14:** 1.2.2의 `count-change` 프로시저가 11센트를 거스름돈으로 만들 때 생성하는 과정을 나타내는 트리를 그려봐. 이 과정이 사용하는 공간과 단계 수의 성장 차수(금액이 증가함에 따라)는 어떻게 될까?

**연습문제 1.15:** 각도(라디안 단위)의 사인 값은 x가 충분히 작으면 $\sin x \approx x$ 근사치를 사용하고, 삼각 항등식 ${\sin x}\, = \,{3\sin\frac{x}{3}}\, - \,{4\sin^{3}\frac{x}{3}}$를 사용하여 사인의 인자 크기를 줄이는 방식으로 계산할 수 있어. (이 연습 문제에서는 각도의 크기가 0.1 라디안보다 크지 않으면 "충분히 작다"고 간주해.) 이러한 아이디어는 다음 프로시저에 포함되어 있어.

Code snippet

```
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
```

1. `(sine 12.15)`가 평가될 때 `p` 프로시저는 몇 번 적용될까?
    
2. `(sine a)`가 평가될 때 `sine` 프로시저가 생성하는 과정이 사용하는 공간과 단계 수의 성장 차수(a의 함수로서)는 어떻게 될까?
    

### 1.2.4 지수 연산 (Exponentiation)

주어진 숫자의 거듭제곱을 계산하는 문제를 생각해 보자. 밑 b와 양의 정수 지수 n을 인자로 받아서 $b^{n}$을 계산하는 프로시저를 만들고 싶어. 한 가지 방법은 재귀 정의를 사용하는 거야.

$$\begin{array}{l}
{b^{n}\, = \, b \cdot b^{n - 1},} \\
{b^{0}\, = \, 1,} \\
\end{array}$$

이것은 다음 프로시저로 쉽게 번역돼.

Code snippet

```
(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
```

이것은 선형 재귀 과정으로, $\Theta(n)$ 단계와 $\Theta(n)$ 공간이 필요해. 계승과 마찬가지로, 동등한 선형 반복을 쉽게 만들 수 있어.

Code snippet

```
(define (expt b n)
  (expt-iter b n 1))

(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                 (- counter 1)
                 (* b product))))
```

이 버전은 $\Theta(n)$ 단계와 $\Theta(1)$ 공간이 필요해.

연속 제곱을 사용하면 더 적은 단계로 지수 연산을 계산할 수 있어. 예를 들어, $b^{8}$을 $b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot b))))))$로 계산하는 대신, 세 번의 곱셈을 사용하여 계산할 수 있어.

$$\begin{array}{l}
{b^{2}\, = \, b \cdot b,} \\
{b^{4}\, = \, b^{2} \cdot b^{2},} \\
{b^{8}\, = \, b^{4} \cdot b^{4}.} \\
\end{array}$$

이 방법은 2의 거듭제곱인 지수에 잘 작동해. 일반적으로 지수 연산을 계산할 때도 연속 제곱의 이점을 활용할 수 있는데, 다음 규칙을 사용하는 거야.

$$\begin{array}{ll}
{b^{n}\, = \,(b^{n/2})^{2}} & {\text{if}\; n\;\text{is\ even},} \\
{b^{n}\, = \, b \cdot b^{n - 1}} & {\text{if}\; n\;\text{is\ odd}.} \\
\end{array}$$

이 방법을 프로시저로 표현할 수 있어.

Code snippet

```
(define (fast-expt b n)
  (cond ((= n 0)
         1)
        ((even? n)
         (square (fast-expt b (/ n 2))))
        (else
         (* b (fast-expt b (- n 1))))))
```

여기서 정수가 짝수인지 테스트하는 술어는 기본 프로시저 `remainder`를 사용하여 정의돼.

Code snippet

```
(define (even? n)
  (= (remainder n 2) 0))
```

`fast-expt`에 의해 진화하는 과정은 공간과 단계 수 모두에서 n에 대해 로그적으로 증가해. 이를 확인하려면, `fast-expt`를 사용하여 $b^{2n}$을 계산하는 데는 $b^{n}$을 계산하는 것보다 단 한 번의 곱셈만 더 필요하다는 점에 주목해. 따라서 우리가 계산할 수 있는 지수의 크기는 우리가 허용하는 새로운 곱셈마다 (대략) 두 배가 돼. 그래서 n 지수에 필요한 곱셈 횟수는 n의 밑이 2인 로그만큼 빠르게 증가해. 이 과정은 $\Theta(\log n)$ 성장을 가져.

$\Theta(\log n)$ 성장과 $\Theta(n)$ 성장의 차이는 n이 커질수록 두드러지게 나타나. 예를 들어, n=1000일 때 `fast-expt`는 단 14번의 곱셈만 필요해. 연속 제곱의 아이디어를 사용하여 로그 단계 수로 지수 연산을 계산하는 반복 알고리즘을 고안할 수도 있지만 (1.16번 연습문제 참조), 반복 알고리즘의 경우 흔히 그렇듯이 재귀 알고리즘만큼 직관적으로 작성되지는 않아.

**연습문제 1.16:** `fast-expt`처럼 연속 제곱을 사용하고 로그 단계 수를 사용하는 반복적인 지수 연산 과정을 진화시키는 프로시저를 설계해봐. (힌트: ${(b^{n/2})^{2}} = {(b^{2})^{n/2}}$라는 관찰을 사용하여, 지수 n과 밑 b 외에 추가적인 상태 변수 a를 유지하고, 상태 변환을 $ab^{n}$ 곱이 상태 간에 변하지 않도록 정의해. 과정 시작 시 a는 1로 간주하며, 답은 과정 종료 시 a의 값으로 주어진다. 일반적으로, 상태 간에 변하지 않는 `불변량(invariant quantity)`을 정의하는 기술은 반복 알고리즘 설계에 대해 생각하는 강력한 방법이야.)

**연습문제 1.17:** 이 섹션의 지수 연산 알고리즘은 반복 곱셈을 통해 지수 연산을 수행하는 것에 기반해. 비슷하게, 반복 덧셈을 통해 정수 곱셈을 수행할 수 있어. 다음 곱셈 프로시저(언어에 곱셈은 없고 덧셈만 가능하다고 가정함)는 `expt` 프로시저와 유사해.

Code snippet

```
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
```

이 알고리즘은 `b`에 선형적인 단계 수를 필요로 해. 이제 덧셈과 함께 정수를 두 배로 만드는 `double` 연산과 짝수 정수를 2로 나누는 `halve` 연산을 포함한다고 가정해봐. 이것들을 사용하여 `fast-expt`와 유사하게 로그 단계 수를 사용하는 곱셈 프로시저를 설계해봐.

**연습문제 1.18:** 1.16번 연습문제와 1.17번 연습문제의 결과를 사용하여, 두 정수를 더하기, 두 배하기, 반으로 나누기를 통해 곱하는 반복 과정을 생성하고 로그 단계 수를 사용하는 프로시저를 고안해봐.

**연습문제 1.19:** 로그 단계 수로 피보나치 수를 계산하는 영리한 알고리즘이 있어. 1.2.2의 `fib-iter` 과정에서 상태 변수 a와 b의 변환을 상기해봐. $a\leftarrow a + b$ 이고 $b\leftarrow a$ 였지. 이 변환을 T라고 부르고, 1과 0에서 시작하여 T를 n번 반복해서 적용하면 $\text{Fib}(n + 1)$, $\text{Fib}(n)$ 쌍이 생성된다는 점에 주목해. 다른 말로 하면, 피보나치 수는 (1,0) 쌍에서 시작하여 변환 T의 n승인 $T^{n}$을 적용하여 생성돼. 이제 T를 변환군 $T_{pq}$에서 p=0, q=1인 특수한 경우라고 생각해보자. 여기서 $T_{pq}$는 쌍 $(a,b)$를 $a\leftarrow{bq} + {aq} + {ap}$와 $b\leftarrow{bp} + {aq}$에 따라 변환해. 이런 변환 $T_{pq}$를 두 번 적용하면 같은 형태의 단일 변환 $T_{p^{\prime}q^{\prime}}$을 사용하는 것과 동일한 효과를 낸다는 것을 보여봐. 그리고 $p^{\prime}$과 $q^{\prime}$을 p와 q로 표현하여 계산해. 이것은 이 변환들을 제곱하는 명시적인 방법을 제공하고, 따라서 `fast-expt` 프로시저처럼 연속 제곱을 사용하여 $T^{n}$을 계산할 수 있어. 이 모든 것을 합쳐서 로그 단계 수로 실행되는 다음 프로시저를 완성해봐.

Code snippet

```
(define (fib n)
  (fib-iter 1 0 0 1 n))

(define (fib-iter a b p q count)
  (cond ((= count 0)
         b)
        ((even? count)
         (fib-iter a
                   b
                   ⟨??⟩  ;compute p'
                   ⟨??⟩  ;compute q'
                   (/ count 2)))
        (else
         (fib-iter (+ (* b q)
                      (* a q)
                      (* a p))
                   (+ (* b p)
                      (* a q))
                   p
                   q
                   (- count 1)))))
```

### 1.2.5 최대 공약수 (Greatest Common Divisors)

두 정수 a와 b의 `최대 공약수(GCD)`는 a와 b를 나머지 없이 나누는 가장 큰 정수로 정의돼. 예를 들어, 16과 28의 GCD는 4야. 2장에서 유리수 연산을 구현하는 방법을 조사할 때, 유리수를 기약분수로 줄이기 위해 GCD를 계산할 수 있어야 할 거야. (유리수를 기약분수로 줄이려면 분자와 분모를 그들의 GCD로 나누어야 해. 예를 들어, 16/28은 4/7로 줄어들어.) 두 정수의 GCD를 찾는 한 가지 방법은 인수분해하여 공통 인수를 찾는 것이지만, 훨씬 더 효율적인 유명한 알고리즘이 있어.

이 알고리즘의 아이디어는 a를 b로 나눴을 때 나머지가 r이라면, a와 b의 공약수가 b와 r의 공약수와 정확히 같다는 관찰에 기반해. 따라서 다음 방정식을 사용하여 GCD를 계산하는 문제를 점점 더 작은 정수 쌍의 GCD를 계산하는 문제로 연속적으로 줄일 수 있어.

Code snippet

```
GCD(a,b) = GCD(b,r)
```

예를 들어,

Code snippet

```
GCD(206,40) = GCD(40,6)
            = GCD(6,4)
            = GCD(4,2)
            = GCD(2,0) = 2
```

GCD(206, 40)를 GCD(2, 0)로 줄여서 2가 돼. 어떤 두 양의 정수에서 시작하여 반복적인 축소를 수행하면 항상 결국 두 번째 숫자가 0인 쌍이 생성된다는 것을 보여줄 수 있어. 그러면 GCD는 그 쌍의 다른 숫자야. GCD를 계산하는 이 방법을 `유클리드 호제법(Euclid’s Algorithm)`이라고 해.

유클리드 호제법을 프로시저로 표현하는 것은 쉬워.

Code snippet

```
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
```

이것은 관련된 숫자의 로그에 따라 단계 수가 증가하는 반복 과정을 생성해.

유클리드 호제법에 필요한 단계 수가 로그적으로 증가한다는 사실은 피보나치 수와 흥미로운 관계를 가지고 있어.

> **라메의 정리(Lamé’s Theorem):** 유클리드 호제법이 어떤 쌍의 GCD를 계산하는 데 k 단계를 필요로 한다면, 그 쌍의 작은 숫자는 k번째 피보나치 수보다 크거나 같아야 해.

우리는 이 정리를 사용하여 유클리드 호제법의 성장 차수를 추정할 수 있어. 프로시저의 두 입력 중 작은 값을 n이라고 하자. 과정이 k 단계를 거친다면, $n \geq \text{Fib}(k) \approx \varphi^{k}/\sqrt{5}$여야 해. 따라서 단계 수 k는 n의 (밑이 $\varphi$인) 로그만큼 증가해. 그러므로 성장 차수는 $\Theta(\log n)$이야.

**연습문제 1.20:** 프로시저가 생성하는 과정은 당연히 인터프리터가 사용하는 규칙에 따라 달라져. 예를 들어, 위에 주어진 반복적인 `gcd` 프로시저를 생각해보자. 1.1.5에서 논의된 일반 순서 평가를 사용하여 이 프로시저를 해석한다고 가정해보자. (`if`에 대한 일반 순서 평가 규칙은 1.5번 연습문제에 설명되어 있어.) (일반 순서에 대한) 대치 방법을 사용하여 `(gcd 206 40)`를 평가할 때 생성되는 과정을 설명하고, 실제로 수행되는 `remainder` 연산들을 표시해봐. `(gcd 206 40)`의 일반 순서 평가에서 실제로 몇 개의 `remainder` 연산이 수행될까? 적용 순서 평가에서는 몇 개가 수행될까?

### 1.2.6 예시: 소수 판별 (Example: Testing for Primality)

이 섹션에서는 정수 n의 소수 여부를 확인하는 두 가지 방법을 설명할 거야. 하나는 성장 차수가 $\Theta(\sqrt{n})$이고, 다른 하나는 성장 차수가 $\Theta(\log n)$인 `확률적 알고리즘`이야. 이 섹션의 끝에 있는 연습 문제들은 이 알고리즘들을 기반으로 한 프로그래밍 프로젝트를 제안하고 있어.

#### 약수 찾기 (Searching for divisors)

고대부터 수학자들은 소수와 관련된 문제에 매료되었고, 많은 사람들이 숫자가 소수인지 테스트하는 방법을 찾는 문제에 대해 연구했어. 숫자가 소수인지 테스트하는 한 가지 방법은 숫자의 약수를 찾는 거야. 다음 프로그램은 주어진 숫자 n의 가장 작은 정수 약수(1보다 큰)를 찾아줘. 이 프로그램은 2부터 시작하여 연속적인 정수로 n이 나누어지는지 테스트하는 직접적인 방식으로 이걸 수행해.

Code snippet

```
(define (smallest-divisor n)
  (find-divisor n 2))

(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n)
         n)
        ((divides? test-divisor n)
         test-divisor)
        (else (find-divisor
               n
               (+ test-divisor 1)))))

(define (divides? a b)
  (= (remainder b a) 0))
```

숫자가 소수인지 아닌지는 다음과 같이 테스트할 수 있어. n은 n이 자신과 가장 작은 약수가 같을 때만 소수야.

Code snippet

```
(define (prime? n)
  (= n (smallest-divisor n)))
```

`find-divisor`의 종료 테스트는 n이 소수가 아니라면 $\sqrt{n}$보다 작거나 같은 약수를 가져야 한다는 사실에 기반해. 이는 알고리즘이 1과 sqrtn 사이의 약수만 테스트하면 된다는 것을 의미해. 결과적으로, n이 소수임을 식별하는 데 필요한 단계 수는 $\Theta(\sqrt{n})$의 성장 차수를 가질 거야.

#### 페르마 테스트 (The Fermat test)

$\Theta(\log n)$ 소수 판별 테스트는 `페르마의 소정리`라고 알려진 정수론 결과에 기반해.

> **페르마의 소정리:** n이 소수이고 a가 n보다 작은 양의 정수라면, a의 n제곱은 n으로 나눈 나머지가 a와 같아.

(두 숫자는 n으로 나눴을 때 나머지가 같으면 `modulo n에 대해 합동`이라고 해. 숫자 a를 n으로 나눈 나머지는 `a modulo n의 나머지` 또는 간단히 `a modulo n`이라고도 불려.)

만약 n이 소수가 아니라면, 일반적으로 n보다 작은 대부분의 a는 위 관계를 만족하지 않을 거야. 이는 다음과 같은 소수 판별 알고리즘으로 이어진다. 숫자 n이 주어졌을 때, n보다 작은 무작위 숫자 a를 선택하고 an을 n으로 나눈 나머지를 계산해. 결과가 a와 같지 않으면 n은 확실히 소수가 아니야. 만약 a라면 n은 소수일 가능성이 높아. 이제 또 다른 무작위 숫자 a를 선택하고 같은 방법으로 테스트해. 그것도 방정식을 만족한다면, 우리는 n이 소수라는 확신을 더 가질 수 있어. 점점 더 많은 a 값을 시도함으로써 결과에 대한 확신을 높일 수 있지. 이 알고리즘을 `페르마 테스트(Fermat test)`라고 해.

페르마 테스트를 구현하려면, 어떤 숫자의 거듭제곱을 다른 숫자로 나눈 나머지를 계산하는 프로시저가 필요해.

Code snippet

```
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (square (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base (expmod base (- exp 1) m))
          m))))
```

이것은 1.2.4의 `fast-expt` 프로시저와 매우 유사해. 연속 제곱을 사용해서, 지수에 따라 단계 수가 로그적으로 증가해.

페르마 테스트는 1과 n−1 사이의 무작위 숫자 a를 선택하고 a의 n제곱을 n으로 나눈 나머지가 a와 같은지 확인하여 수행돼. 무작위 숫자 a는 Scheme에 기본으로 포함되어 있다고 가정하는 `random` 프로시저를 사용하여 선택해. `random`은 정수 입력보다 작은 음이 아닌 정수를 반환해. 따라서 1과 n−1 사이의 무작위 숫자를 얻으려면 `random`을 n−1을 입력으로 호출하고 결과에 1을 더해줘.

Code snippet

```
(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
```

다음 프로시저는 매개변수로 지정된 횟수만큼 테스트를 실행해. 테스트가 매번 성공하면 참(true)이고, 그렇지 않으면 거짓(false)이야.

Code snippet

```
(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n)
         (fast-prime? n (- times 1)))
        (else false)))
```

#### 확률적 방법 (Probabilistic methods)

페르마 테스트는 대부분의 익숙한 알고리즘과 성격이 달라. 대부분의 알고리즘은 정답이 보장되는 답을 계산하지만, 페르마 테스트에서 얻은 답은 `아마도` 맞을 뿐이야. 더 정확히 말하면, n이 페르마 테스트에 한 번이라도 실패하면 n은 소수가 아니라는 것을 확신할 수 있어. 하지만 n이 테스트를 통과하더라도 이는 매우 강력한 지표일 뿐, n이 소수라는 보장은 아니야. 우리가 말하고 싶은 것은 어떤 숫자 n에 대해 테스트를 충분히 많이 수행하고 n이 항상 테스트를 통과한다면, 소수 판별 테스트의 오류 확률을 원하는 만큼 작게 만들 수 있다는 거야.

안타깝게도 이 주장은 완전히 정확하지 않아. 페르마 테스트를 속이는 숫자들이 존재해. 즉, 소수가 아니지만 n보다 작은 모든 정수 a에 대해 $a^{n}$이 modulo n에 대해 a와 합동인 속성을 가진 숫자들 말이야. 이런 숫자들은 매우 드물기 때문에 페르마 테스트는 실제로는 꽤 신뢰할 수 있어.

페르마 테스트를 속일 수 없는 변형들이 있어. 이 테스트들에서도 페르마 방법과 마찬가지로, 정수 n의 소수 여부를 테스트하기 위해 n보다 작은 무작위 정수 a를 선택하고 n과 a에 따라 달라지는 어떤 조건을 확인해. (이러한 테스트의 예시는 1.28번 연습문제에서 볼 수 있어.) 반면에, 페르마 테스트와 대조적으로, n이 소수가 아니라면, n보다 작은 정수 a의 대부분에 대해 조건이 성립하지 않는다는 것을 증명할 수 있어. 따라서 n이 무작위로 선택된 a에 대해 테스트를 통과하면 n이 소수일 확률이 50%보다 높아. n이 두 번의 무작위 a 선택에 대해 테스트를 통과하면 n이 소수일 확률이 4분의 3보다 높아. 점점 더 많은 무작위 a 값을 사용하여 테스트를 실행함으로써 오류 확률을 원하는 만큼 작게 만들 수 있어.

오류 가능성을 임의로 작게 만들 수 있다는 것을 증명할 수 있는 테스트의 존재는 이러한 유형의 알고리즘에 대한 관심을 불러일으켰고, 이를 `확률적 알고리즘(probabilistic algorithms)`이라고 부르게 되었어. 이 분야에는 많은 연구 활동이 진행 중이며, 확률적 알고리즘은 많은 분야에 성공적으로 적용되었어.

**연습문제 1.21:** `smallest-divisor` 프로시저를 사용하여 다음 각 숫자의 가장 작은 약수를 찾아봐: 199, 1999, 19999.

**연습문제 1.22:** 대부분의 Lisp 구현에는 시스템이 실행된 시간(예: 마이크로초 단위)을 지정하는 정수를 반환하는 `runtime`이라는 기본 기능이 포함되어 있어. 다음 `timed-prime-test` 프로시저는 정수 n으로 호출될 때 n을 출력하고 n이 소수인지 확인해. 만약 n이 소수이면, 프로시저는 세 개의 별표와 함께 테스트를 수행하는 데 걸린 시간을 출력해.

Code snippet

```
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
```

Code snippet

```
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime)
                       start-time))))
```

Code snippet

```
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
```

이 프로시저를 사용하여 지정된 범위에서 연속적인 홀수 정수의 소수 여부를 확인하는 `search-for-primes` 프로시저를 작성해봐. 이 프로시저를 사용하여 1000보다 큰 가장 작은 세 개의 소수, 10,000보다 큰 소수, 100,000보다 큰 소수, 1,000,000보다 큰 소수를 찾아봐. 각 소수를 테스트하는 데 걸린 시간을 기록해. 테스트 알고리즘의 성장 차수가 $\Theta(\sqrt{n})$이므로, 10,000 주변의 소수를 테스트하는 데는 1000 주변의 소수를 테스트하는 것보다 약 $\sqrt{10}$배 더 오래 걸릴 것으로 예상할 수 있어. 네 타이밍 데이터가 이를 뒷받침하니? 100,000과 1,000,000에 대한 데이터는 $\Theta(\sqrt{n})$ 예측을 얼마나 잘 지지할까? 네 컴퓨터의 프로그램이 계산에 필요한 단계 수에 비례하는 시간으로 실행된다는 개념과 결과가 일치하니?

**연습문제 1.23:** 이 섹션 시작 부분에 있는 `smallest-divisor` 프로시저는 불필요한 테스트를 많이 해: 숫자가 2로 나누어지는지 확인한 후에는 더 큰 짝수로 나누어지는지 확인할 필요가 없어. 이는 `test-divisor`에 사용되는 값이 2, 3, 4, 5, 6, …이 아니라 2, 3, 5, 7, 9, …여야 한다는 것을 시사해. 이 변경 사항을 구현하려면, 입력이 2와 같으면 3을 반환하고 그렇지 않으면 입력에 2를 더한 값을 반환하는 `next` 프로시저를 정의해봐. `smallest-divisor` 프로시저를 수정하여 `(+ test-divisor 1)` 대신 `(next test-divisor)`를 사용하도록 해. 이 수정된 버전의 `smallest-divisor`를 포함한 `timed-prime-test`로, 1.22번 연습문제에서 찾은 12개의 소수 각각에 대해 테스트를 실행해봐. 이 수정으로 테스트 단계 수가 절반으로 줄어들기 때문에, 약 두 배 더 빠르게 실행될 것으로 예상할 수 있어. 이 예상은 확인될까? 그렇지 않다면, 두 알고리즘의 속도 비율은 얼마이며, 그것이 2와 다른 이유를 어떻게 설명할 수 있을까?

**연습문제 1.24:** 1.22번 연습문제의 `timed-prime-test` 프로시저를 `fast-prime?` (페르마 방법)를 사용하도록 수정하고, 그 연습문제에서 찾은 12개의 소수 각각을 테스트해봐. 페르마 테스트는 $\Theta(\log n)$ 성장을 가지므로, 1,000,000 근처의 소수를 테스트하는 시간이 1000 근처의 소수를 테스트하는 시간과 어떻게 비교될 것으로 예상할까? 네 데이터가 이를 뒷받침하니? 발견한 불일치를 설명할 수 있을까?

**연습문제 1.25:** 앨리사 P. 해커는 `expmod`를 작성하는 데 많은 추가 노력을 기울였다고 불평했어. 결국, 그녀는 우리가 이미 지수 연산을 계산하는 방법을 알고 있으니, 단순히 다음과 같이 작성할 수도 있었다고 말해.

Code snippet

```
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
```

그녀가 옳을까? 이 프로시저가 우리의 빠른 소수 판별기에도 똑같이 잘 작동할까? 설명해봐.

**연습문제 1.26:** 루이스 리즈너는 1.24번 연습문제를 푸는 데 큰 어려움을 겪고 있어. 그의 `fast-prime?` 테스트가 `prime?`테스트보다 더 느리게 실행되는 것 같거든. 루이스는 친구 이바 루 에이토어에게 도움을 요청했어. 그들이 루이스의 코드를 살펴보니, 그가 `expmod` 프로시저를 `square`를 호출하는 대신 명시적인 곱셈을 사용하도록 다시 작성했다는 것을 알게 됐어.

Code snippet

```
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (* (expmod base (/ exp 2) m)
             (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base
             (expmod base (- exp 1) m))
          m))))
```

"무슨 차이가 있을지 모르겠어." 루이스가 말했어. "나는 알아." 이바가 말했어. "프로시저를 그렇게 작성함으로써, 너는 $\Theta(\log n)$ 과정을 $\Theta(n)$ 과정으로 바꿔 버린 거야." 설명해봐.

**연습문제 1.27:** 각주 47에 나열된 카마이클 수가 실제로 페르마 테스트를 속인다는 것을 증명해봐. 즉, 정수 n을 받아서 n보다 작은 모든 a에 대해 $a^{n}$이 modulo n에 대해 a와 합동인지 테스트하는 프로시저를 작성하고, 주어진 카마이클 수에 대해 네 프로시저를 시도해봐.

**연습문제 1.28:** 속일 수 없는 페르마 테스트 변형 중 하나는 `밀러-라빈 테스트(Miller-Rabin test)`라고 불려. 이것은 페르마의 소정리의 다른 형태에서 시작하는데, n이 소수이고 a가 n보다 작은 양의 정수라면, a의 $(n-1)$제곱은 modulo n에 대해 1과 합동이라고 말해. 밀러-라빈 테스트로 숫자 n의 소수 여부를 테스트하려면, n보다 작은 무작위 숫자 a를 선택하고 `expmod` 프로시저를 사용하여 a를 $(n-1)$제곱한 후 modulo n 값을 구해. 하지만, `expmod`에서 제곱 단계를 수행할 때마다, `modulo n에 대한 비자명한 1의 제곱근`을 발견했는지 확인해. 즉, 1 또는 n−1이 아닌 숫자인데 그 제곱이 modulo n에 대해 1과 같은 숫자 말이야. 이런 비자명한 1의 제곱근이 존재한다면 n은 소수가 아니라는 것을 증명할 수 있어. 또한 n이 소수가 아닌 홀수라면, n보다 작은 숫자 a의 적어도 절반에 대해 이런 방식으로 $a^{n-1}$을 계산하면 modulo n에 대한 비자명한 1의 제곱근이 드러난다는 것을 증명할 수 있어. (이것이 밀러-라빈 테스트가 속일 수 없는 이유야.) `expmod` 프로시저를 수정하여 비자명한 1의 제곱근을 발견하면 신호를 보내도록 하고, 이를 사용하여 `fermat-test`와 유사한 프로시저로 밀러-라빈 테스트를 구현해봐. 알려진 다양한 소수와 비소수를 테스트하여 프로시저를 확인해봐. 힌트: `expmod`가 신호를 보내는 한 가지 편리한 방법은 0을 반환하도록 하는 거야.