이제 프로그래밍의 요소들을 살펴보았습니다. 기본 산술 연산을 사용했고, 이 연산들을 결합했으며, 이 복합 연산들을 복합 프로시저로 정의하여 추상화했습니다. 그러나 이것만으로는 우리가 프로그래밍을 할 줄 안다고 말하기에 충분하지 않습니다. 우리의 상황은 체스의 기물 이동 규칙은 배웠지만, 전형적인 오프닝, 전술 또는 전략에 대해서는 아무것도 모르는 사람의 상황과 유사합니다. 초보 체스 플레이어처럼, 우리는 아직 해당 분야에서 흔히 사용되는 패턴을 알지 못합니다. 우리는 어떤 움직임이 가치 있는지(어떤 프로시저를 정의할 가치가 있는지) 알지 못합니다. 우리는 움직임(프로시저 실행)의 결과를 예측할 경험이 부족합니다.

고려 중인 행동의 결과를 시각화하는 능력은 모든 합성적이고 창의적인 활동에서와 마찬가지로 숙련된 프로그래머가 되는 데 중요합니다. 예를 들어, 숙련된 사진가가 되려면 장면을 보고 노출 및 현상 조건의 각 가능한 선택에 대해 각 영역이 인쇄물에 얼마나 어둡게 나타날지 알아야 합니다. 그래야만 역으로 추론하여 원하는 효과를 얻기 위해 구도, 조명, 노출, 현상을 계획할 수 있습니다. 마찬가지로 프로그래밍에서도 프로세스가 수행할 행동 과정을 계획하고 프로그램 수단을 통해 프로세스를 제어합니다. 전문가가 되기 위해서는 다양한 유형의 프로시저가 생성하는 프로세스를 시각화하는 방법을 배워야 합니다. 이러한 기술을 개발한 후에야 원하는 동작을 나타내는 프로그램을 안정적으로 구성하는 방법을 배울 수 있습니다.

프로시저는 계산 과정의 _지역적 진화_를 위한 패턴입니다. 그것은 과정의 각 단계가 이전 단계 위에 어떻게 구축되는지를 명시합니다. 우리는 지역적 진화가 프로시저에 의해 지정된 과정의 전체적인, 또는 _전역적인_ 동작에 대해 진술할 수 있기를 원합니다. 이것은 일반적으로 매우 어렵지만, 적어도 과정 진화의 몇 가지 전형적인 패턴을 설명하려고 노력할 수 있습니다.

이 섹션에서는 간단한 프로시저에 의해 생성되는 프로세스의 일반적인 "형태"를 살펴볼 것입니다. 또한 이러한 프로세스가 시간과 공간이라는 중요한 계산 자원을 소비하는 속도도 조사할 것입니다. 우리가 고려할 프로시저는 매우 간단합니다. 그들의 역할은 사진의 테스트 패턴과 같습니다. 즉, 그 자체로 실용적인 예시라기보다는 지나치게 단순화된 원형 패턴입니다.

## 1.2.1 선형 재귀와 반복

팩토리얼 함수를 고려하는 것부터 시작합니다. $n! = {n \cdot (n - 1)} \cdot {(n - 2)}\cdots{3 \cdot 2 \cdot 1}$로 정의됩니다. 팩토리얼을 계산하는 방법은 여러 가지가 있습니다. 한 가지 방법은 양의 정수 n에 대해 $n!$이 n에 $(n - 1)!$을 곱한 것과 같다는 관찰을 활용하는 것입니다.

$$n!\, = \,{n \cdot \lbrack(n - 1)} \cdot {(n - 2)}\cdots{3 \cdot 2 \cdot 1\rbrack}\, = \,{n \cdot (n - 1)!.}$$

따라서 우리는 $(n - 1)!$을 계산하고 그 결과에 n을 곱함으로써 $n!$을 계산할 수 있습니다. $1!$이 1과 같다는 조건을 추가하면, 이 관찰은 직접적으로 프로시저로 변환됩니다.

코드 스니펫

```
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
```

1.1.5절 의 대치 모델을 사용하여 이 프로시저가 6!을 계산하는 과정을 [그림 1.3](https://www.google.com/search?q=%23Figure-1_002e3)에서 볼 수 있습니다.

![](./images/ch1-Z-G-7.gif)

그림 1.3: 6!을 계산하는 선형 재귀 과정.

이제 팩토리얼을 계산하는 다른 관점을 취해봅시다. 우리는 1에 2를 곱하고, 그 결과에 3을 곱하고, 다시 4를 곱하는 식으로 n에 도달할 때까지 계속 곱함으로써 $n!$을 계산하는 규칙을 설명할 수 있습니다. 더 공식적으로는, 실행 중인 곱과 1부터 n까지 세는 카운터를 유지합니다. 계산은 다음 규칙에 따라 카운터와 곱이 한 단계에서 다음 단계로 동시에 변경된다고 설명할 수 있습니다.

코드 스니펫

```
product
  ←
 counter * product
counter
  ←
 counter + 1
```

그리고 카운터가 n을 초과할 때 곱의 값이 $n!$이라고 규정합니다.

다시 한번, 우리는 팩토리얼을 계산하는 프로시저로 우리의 설명을 재구성할 수 있습니다.^[실제 프로그램에서는 지난 섹션에서 소개된 블록 구조를 사용하여 `fact-iter`의 정의를 숨길 것입니다.]

코드 스니펫

```
(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
```

이전과 마찬가지로, [그림 1.4](https://www.google.com/search?q=%23Figure-1_002e4)에서 6!을 계산하는 과정을 시각화하기 위해 대치 모델을 사용할 수 있습니다.

![](./images/ch1-Z-G-10.gif)

그림 1.4: 6!을 계산하는 선형 반복 과정.

두 프로세스를 비교해 봅시다. 어떤 관점에서 보면 전혀 다르지 않은 것 같습니다. 둘 다 동일한 수학 함수를 동일한 도메인에서 계산하며, 각각 $n!$을 계산하는 데 n에 비례하는 단계 수가 필요합니다. 실제로 두 프로세스 모두 동일한 곱셈 시퀀스를 수행하여 동일한 부분 곱 시퀀스를 얻습니다. 반면에 두 프로세스의 "형태"를 고려하면 상당히 다르게 진화한다는 것을 알 수 있습니다.

첫 번째 과정을 생각해 봅시다. 대치 모델은 [그림 1.3](https://www.google.com/search?q=%23Figure-1_002e3)의 화살표로 표시된 확장 후 축소의 형태를 보여줍니다. 확장은 과정이 _지연된 연산_의 사슬(이 경우 곱셈 사슬)을 구축하면서 발생합니다. 축소는 연산이 실제로 수행될 때 발생합니다. 지연된 연산의 사슬이 특징인 이러한 유형의 과정을 _재귀 과정_이라고 합니다. 이 과정을 수행하려면 인터프리터가 나중에 수행될 연산을 추적해야 합니다. n 계산에서 지연된 곱셈 사슬의 길이, 따라서 이를 추적하는 데 필요한 정보의 양은 단계 수와 마찬가지로 n에 선형적으로 증가합니다( n에 비례합니다). 이러한 과정을 _선형 재귀 과정_이라고 합니다.

대조적으로, 두 번째 프로세스는 증가하거나 감소하지 않습니다. 각 단계에서 어떤 n에 대해서든 추적해야 하는 것은 `product`, `counter`, `max-count` 변수의 현재 값뿐입니다. 우리는 이것을 _반복 프로세스_라고 부릅니다. 일반적으로 반복 프로세스는 고정된 수의 _상태 변수_와 함께, 프로세스가 상태에서 상태로 이동할 때 상태 변수가 어떻게 업데이트되어야 하는지를 설명하는 고정된 규칙, 그리고 프로세스가 종료되어야 하는 조건을 지정하는 (선택적) 종료 테스트로 상태를 요약할 수 있는 프로세스입니다. $n!$을 계산할 때 필요한 단계 수는 n에 선형적으로 증가합니다. 이러한 프로세스를 _선형 반복 프로세스_라고 합니다.

두 프로세스 간의 대조는 다른 방식으로도 볼 수 있습니다. 반복의 경우, 프로그램 변수는 어떤 시점에서든 프로세스의 상태를 완벽하게 설명합니다. 만약 우리가 단계 사이에 계산을 멈춘다면, 계산을 재개하기 위해 필요한 모든 것은 인터프리터에 세 가지 프로그램 변수의 값을 제공하는 것입니다. 재귀 프로세스는 그렇지 않습니다. 이 경우 인터프리터에 의해 유지되고 프로그램 변수에 포함되지 않는 "숨겨진" 추가 정보가 있어 지연된 연산의 사슬을 처리하는 데 "프로세스가 어디에 있는지"를 나타냅니다. 사슬이 길어질수록 더 많은 정보가 유지되어야 합니다.^[5장 에서 레지스터 머신에서 프로시저 구현을 논의할 때, 모든 반복 프로세스는 보조 메모리 없이 고정된 레지스터 세트를 가진 머신으로 "하드웨어에서" 구현될 수 있음을 알게 될 것입니다. 대조적으로, 재귀 프로세스를 구현하려면 _스택_으로 알려진 보조 데이터 구조를 사용하는 머신이 필요합니다.]

반복과 재귀를 대조할 때, 우리는 재귀 _프로세스_의 개념과 재귀 _프로시저_의 개념을 혼동하지 않도록 주의해야 합니다. 프로시저를 재귀적이라고 설명할 때, 우리는 프로시저 정의가 (직접 또는 간접적으로) 프로시저 자체를 참조한다는 구문적 사실을 언급합니다. 그러나 프로세스가 선형 재귀적이라고 말할 때, 우리는 프로세스가 어떻게 진화하는지에 대해 말하는 것이지, 프로시저가 어떻게 작성되었는지의 구문에 대해 말하는 것이 아닙니다. `fact-iter`와 같은 재귀 프로시저가 반복 프로세스를 생성한다고 언급하는 것이 혼란스러워 보일 수 있습니다. 그러나 이 프로세스는 실제로 반복적입니다. 그 상태는 세 가지 상태 변수에 의해 완전히 포착되며, 인터프리터는 프로세스를 실행하기 위해 세 가지 변수만 추적하면 됩니다.

프로세스와 프로시저의 구별이 혼란스러울 수 있는 한 가지 이유는 Ada, Pascal, C를 포함한 일반적인 언어의 대부분의 구현이 재귀 프로시저의 해석이 원칙적으로 반복적인 프로세스라 할지라도 프로시저 호출 횟수에 따라 메모리 양을 소비하도록 설계되어 있기 때문입니다. 결과적으로 이러한 언어는 `do`, `repeat`, `until`, `for`, `while`과 같은 특수 목적의 "루핑 구문"에 의존해야만 반복 프로세스를 설명할 수 있습니다. 5장에서 살펴볼 Scheme 구현은 이러한 결함을 공유하지 않습니다. 반복 프로세스가 재귀 프로시저로 기술되더라도 상수 공간에서 반복 프로세스를 실행합니다. 이러한 속성을 가진 구현을 _꼬리 재귀적_이라고 합니다. 꼬리 재귀적 구현에서는 일반적인 프로시저 호출 메커니즘을 사용하여 반복을 표현할 수 있으므로 특수 반복 구문은 구문 설탕으로만 유용합니다.^[꼬리 재귀는 오랫동안 컴파일러 최적화 기법으로 알려져 있었습니다. 꼬리 재귀에 대한 일관된 의미론적 기반은 Carl Hewitt(1977)에 의해 제공되었는데, 그는 이를 3장 에서 논의할 "메시지 전달" 계산 모델로 설명했습니다. 이에 영감을 받아 Gerald Jay Sussman과 Guy Lewis Steele Jr. (Steele and Sussman 1975 참조)는 Scheme용 꼬리 재귀 인터프리터를 구축했습니다. Steele은 나중에 꼬리 재귀가 프로시저 호출을 컴파일하는 자연스러운 방법의 결과임을 보여주었습니다 (Steele 1977). Scheme의 IEEE 표준은 Scheme 구현이 꼬리 재귀적이어야 한다고 요구합니다.]

**연습문제 1.9:** 다음 두 프로시저는 각각 인수를 1 증가시키는 `inc`와 인수를 1 감소시키는 `dec` 프로시저를 사용하여 두 양의 정수를 더하는 방법을 정의합니다.

코드 스니펫

```
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
```

대치 모델을 사용하여 `(+ 4 5)`를 평가할 때 각 프로시저가 생성하는 프로세스를 설명하시오. 이 프로세스들은 반복적인가요, 재귀적인가요?

**연습문제 1.10:** 다음 프로시저는 아커만(Ackermann) 함수라고 불리는 수학적 함수를 계산합니다.

코드 스니펫

```
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
```

다음 표현식의 값은 무엇입니까?

코드 스니펫

```
(A 1 10)
(A 2 4)
(A 3 3)
```

위에서 정의된 `A` 프로시저를 사용하여 다음 프로시저를 고려하십시오.

코드 스니펫

```
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
```

양의 정수 n에 대해 프로시저 `f`, `g`, `h`가 계산하는 함수에 대한 간결한 수학적 정의를 제시하시오. 예를 들어, `(k n)`은 $5n^{2}$를 계산합니다.

## 1.2.2 트리 재귀

또 다른 일반적인 계산 패턴은 _트리 재귀_라고 불립니다. 예를 들어, 각 숫자가 이전 두 숫자의 합인 피보나치 수열을 계산하는 것을 생각해 봅시다.

0, 1, 1, 2, 3, 5, 8, 13, 21, ….

일반적으로 피보나치 수는 다음과 같은 규칙으로 정의할 수 있습니다.

$$\text{Fib}(n)\; = \;\begin{cases}
0 & {\;\text{if}\;\; n = 0,} \\
1 & {\;\text{if}\;\; n = 1,} \\
{\text{Fib}(n - 1) + \text{Fib}(n - 2)} & {\;\text{otherwise}.} \\
\end{cases}$$

이 정의를 피보나치 수를 계산하는 재귀 프로시저로 즉시 변환할 수 있습니다.

코드 스니펫

```
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
```

이 계산의 패턴을 고려해 봅시다. `(fib 5)`를 계산하려면 `(fib 4)`와 `(fib 3)`을 계산합니다. `(fib 4)`를 계산하려면 `(fib 3)`과 `(fib 2)`를 계산합니다. 일반적으로 진화된 프로세스는 [그림 1.5](https://www.google.com/search?q=%23Figure-1_002e5)에 표시된 것처럼 트리처럼 보입니다. 가지가 각 수준에서 (맨 아래를 제외하고) 두 개로 갈라지는 것을 주목하십시오. 이는 `fib` 프로시저가 호출될 때마다 두 번 자신을 호출한다는 사실을 반영합니다.

![](./images/ch1-Z-G-13.gif)

그림 1.5: (fib 5) 계산에서 생성된 트리 재귀 프로세스.

이 프로시저는 전형적인 트리 재귀로서 유익하지만, 너무 많은 중복 계산을 하기 때문에 피보나치 수를 계산하는 데는 끔찍한 방법입니다. [그림 1.5](https://www.google.com/search?q=%23Figure-1_002e5)에서 `(fib 3)`의 전체 계산(거의 절반의 작업)이 중복되는 것을 주목하십시오. 사실, 프로시저가 `(fib 1)` 또는 `(fib 0)`을 계산하는 횟수(일반적으로 위 트리의 잎 수)가 정확히 $\text{Fib}(n + 1)$임을 보이는 것은 어렵지 않습니다. 이것이 얼마나 나쁜지 알아보기 위해, $\text{Fib}(n)$의 값이 n에 따라 기하급수적으로 증가한다는 것을 보일 수 있습니다. 더 정확하게는 (연습 1.13 참조), $\text{Fib}(n)$은 $\varphi^{n}/\sqrt{5}$에 가장 가까운 정수이며, 여기서

$$\varphi\, = \,\frac{1 + \sqrt{5}}{2}\, \approx \, 1.6180$$

은 _황금 비율_이며, 방정식 $\varphi^{2} = {\varphi + 1}$을 만족합니다. 따라서 이 프로세스는 입력에 따라 기하급수적으로 증가하는 단계 수를 사용합니다. 반면에 필요한 공간은 입력에 선형적으로만 증가합니다. 왜냐하면 계산의 어느 시점에서든 트리의 위쪽에 있는 노드만 추적하면 되기 때문입니다. 일반적으로 트리 재귀 프로세스에 필요한 단계 수는 트리의 노드 수에 비례하며, 필요한 공간은 트리의 최대 깊이에 비례합니다.

피보나치 수를 계산하기 위한 반복 프로세스도 공식화할 수 있습니다. 아이디어는 정수 쌍 a와 b를 사용하여 $\text{Fib(1)\ =\ 1}$과 $\text{Fib(0)\ =\ 0}$으로 초기화하고, 다음 동시 변환을 반복적으로 적용하는 것입니다.

$$\begin{array}{l}
{a\;\leftarrow\; a + b,} \\
{b\;\leftarrow\; a.} \\
\end{array}$$

이 변환을 n번 적용하면 a와 b가 각각 $\text{Fib}(n + 1)$과 $\text{Fib}(n)$과 같아진다는 것을 보이는 것은 어렵지 않습니다. 따라서 다음 프로시저를 사용하여 피보나치 수를 반복적으로 계산할 수 있습니다.

코드 스니펫

```
(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
```

$\text{Fib}(n)$을 계산하는 이 두 번째 방법은 선형 반복입니다. 두 방법(하나는 n에 선형적이고, 다른 하나는 textFib(n) 자체만큼 빠르게 증가)에 필요한 단계 수의 차이는 작은 입력에서도 엄청납니다.

이것으로부터 트리 재귀 프로세스가 쓸모없다고 결론 내서는 안 됩니다. 숫자 대신 계층적으로 구조화된 데이터를 다루는 프로세스를 고려할 때 트리 재귀가 자연스럽고 강력한 도구임을 알게 될 것입니다.^[이에 대한 예시는 1.1.3절 에서 암시되었습니다. 인터프리터 자체는 트리 재귀 프로세스를 사용하여 표현식을 평가합니다.] 그러나 숫자 연산에서도 트리 재귀 프로세스는 프로그램을 이해하고 설계하는 데 유용할 수 있습니다. 예를 들어, 첫 번째 `fib` 프로시저는 두 번째 프로시저보다 훨씬 덜 효율적이지만, 피보나치 수열 정의를 Lisp로 번역한 것과 거의 다르지 않아 더 간단합니다. 반복 알고리즘을 공식화하려면 세 가지 상태 변수를 사용하여 계산을 반복으로 재구성할 수 있음을 알아차려야 했습니다.

### 예시: 거스름돈 계산

반복 피보나치 알고리즘을 고안하는 데는 약간의 영리함만 있으면 됩니다. 반면에 다음 문제를 생각해 봅시다. 반달러, 쿼터, 다임, 니켈, 페니가 주어졌을 때 1달러를 거스름돈으로 만들 수 있는 방법은 몇 가지입니까? 더 일반적으로, 주어진 금액을 거스름돈으로 만들 수 있는 방법의 수를 계산하는 프로시저를 작성할 수 있을까요?

이 문제는 재귀 프로시저로 간단한 해결책을 가지고 있습니다. 사용 가능한 동전의 종류를 어떤 순서로 배열했다고 가정해 봅시다. 그러면 다음 관계가 성립합니다.

n가지 종류의 동전을 사용하여 금액 a를 거스름돈으로 만들 수 있는 방법의 수는 다음과 같습니다.

- 첫 번째 종류의 동전을 제외한 모든 동전을 사용하여 금액 a를 거스름돈으로 만들 수 있는 방법의 수 더하기,
    
- 첫 번째 종류의 동전의 액면가 d일 때, n가지 종류의 동전을 사용하여 금액 a−d를 거스름돈으로 만들 수 있는 방법의 수
    

이것이 왜 사실인지 알아보기 위해 거스름돈을 만드는 방법을 두 그룹으로 나눌 수 있습니다: 첫 번째 종류의 동전을 사용하지 않는 방법과 사용하는 방법. 따라서 어떤 금액에 대한 거스름돈을 만드는 총 방법의 수는 첫 번째 종류의 동전을 사용하지 않고 금액에 대한 거스름돈을 만드는 방법의 수와 첫 번째 종류의 동전을 사용한다고 가정하고 거스름돈을 만드는 방법의 수를 더한 것과 같습니다. 그러나 후자의 수는 첫 번째 종류의 동전을 사용한 후 남은 금액에 대한 거스름돈을 만드는 방법의 수와 같습니다.

따라서 주어진 금액을 거스름돈으로 바꾸는 문제를 더 적은 종류의 동전을 사용하여 더 적은 금액을 거스름돈으로 바꾸는 문제로 재귀적으로 줄일 수 있습니다. 이 감소 규칙을 주의 깊게 고려하고, 다음 퇴화 사례를 지정하면 알고리즘을 설명하는 데 사용할 수 있음을 스스로 납득시키십시오.^[예를 들어, 10센트를 페니와 니켈을 사용하여 거스름돈으로 만드는 문제에 감소 규칙이 어떻게 적용되는지 자세히 살펴보십시오.]

- a가 정확히 0이면, 거스름돈을 만들 수 있는 방법이 1가지로 간주되어야 합니다.
    
- a가 0보다 작으면, 거스름돈을 만들 수 있는 방법이 0가지로 간주되어야 합니다.
    
- n이 0이면, 거스름돈을 만들 수 있는 방법이 0가지로 간주되어야 합니다.
    

이 설명을 재귀 프로시저로 쉽게 변환할 수 있습니다.

코드 스니펫

```
(define (count-change amount)
  (cc amount 5))

(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0)
             (= kinds-of-coins 0))
         0)
        (else
         (+ (cc amount (- kinds-of-coins 1))
            (cc (- amount (first-denomination
                           kinds-of-coins))
                kinds-of-coins)))))

(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
```

(`first-denomination` 프로시저는 사용 가능한 동전 종류의 수를 입력으로 받아 첫 번째 종류의 액면가를 반환합니다. 여기서는 동전을 가장 큰 것부터 가장 작은 것 순서로 배열한다고 생각하지만, 어떤 순서든 상관없습니다.) 이제 1달러 거스름돈에 대한 원래 질문에 답할 수 있습니다.

코드 스니펫

```
(count-change 100)
292
```

`Count-change`는 `fib`의 첫 번째 구현과 유사한 중복성을 가진 트리 재귀 프로세스를 생성합니다. (292가 계산되는 데 꽤 시간이 걸릴 것입니다.) 반면에 결과를 계산하는 더 나은 알고리즘을 설계하는 방법은 명확하지 않으며, 이 문제는 과제로 남겨둡니다. 트리 재귀 프로세스는 매우 비효율적일 수 있지만 종종 지정하고 이해하기 쉽다는 관찰은 사람들이 트리 재귀 프로시저를 동일한 결과를 계산하는 더 효율적인 프로시저로 변환할 수 있는 "스마트 컴파일러"를 설계함으로써 두 가지 장점을 모두 얻을 수 있다고 제안하도록 이끌었습니다.^[중복 계산에 대처하는 한 가지 방법은 계산된 값을 자동으로 테이블로 구성하도록 조정하는 것입니다. 프로시저를 어떤 인수에 적용하라는 요청을 받을 때마다 먼저 값이 테이블에 이미 저장되어 있는지 확인하여 중복 계산을 피합니다. _표준화_ 또는 _메모화_로 알려진 이 전략은 간단한 방식으로 구현할 수 있습니다. 표준화는 때때로 지수적인 단계 수를 요구하는 프로세스(예: `count-change`)를 공간 및 시간 요구 사항이 입력과 선형적으로 증가하는 프로세스로 변환하는 데 사용될 수 있습니다. 3.27절 을 참조하십시오.]

**연습문제 1.11:** 함수 f는 $n \< 3$일 때 f(n)=n이고, ngeq3일 때 ${f(n)} = {f(n - 1)} + {2f(n - 2)} + {3f(n - 3)}$이라는 규칙으로 정의됩니다. 재귀 프로세스를 사용하여 f를 계산하는 프로시저를 작성하시오. 반복 프로세스를 사용하여 f를 계산하는 프로시저를 작성하시오.

**연습문제 1.12:** 다음 숫자 패턴을 _파스칼의 삼각형_이라고 합니다.

코드 스니펫

```
         1
       1   1
     1   2   1
   1   3   3   1
 1   4   6   4   1
       . . .
```

삼각형의 가장자리에 있는 숫자는 모두 1이고, 삼각형 안의 각 숫자는 그 위에 있는 두 숫자의 합입니다.^[파스칼의 삼각형의 요소들은 _이항 계수_라고 불립니다. 왜냐하면 ntextth 행은 $(x + y)^{n}$의 전개에서 항의 계수들로 구성되기 때문입니다. 계수를 계산하는 이 패턴은 블레즈 파스칼의 1653년 확률론에 대한 중요한 저서인 Traité du triangle arithmétique에 나타났습니다. Knuth (1973)에 따르면, 동일한 패턴이 1303년 중국 수학자 주스시지에(Chu Shih-chieh)가 출판한 『사원옥감(四元玉鑑)』, 12세기 페르시아 시인이자 수학자 오마르 하이얌의 저서, 12세기 힌두 수학자 바스카라 아차리아의 저서에도 나타납니다.] 재귀 프로세스를 사용하여 파스칼의 삼각형 요소를 계산하는 프로시저를 작성하시오.

**연습문제 1.13:** $\text{Fib}(n)$이 $\varphi^{n}/\sqrt{5}$에 가장 가까운 정수임을 증명하시오. 단, $\varphi = {(1 + \sqrt{5})/2}$이다. 힌트: $\psi = {(1 - \sqrt{5})/2}$라고 하자. 귀납법과 피보나치 수의 정의(1.2.2절 참조)를 사용하여 ${\text{Fib}(n)} = {(\varphi^{n} - \psi^{n})/\sqrt{5}}$임을 증명하시오.

## 1.2.3 성장 차수

이전 예시는 프로세스가 계산 자원을 소비하는 속도에서 상당히 다를 수 있음을 보여줍니다. 이러한 차이를 설명하는 한 가지 편리한 방법은 _성장 차수_ 개념을 사용하여 입력이 커짐에 따라 프로세스가 필요로 하는 자원의 대략적인 측정치를 얻는 것입니다.

n을 문제의 크기를 측정하는 매개변수라고 하고, $R(n)$을 크기 n의 문제에 대해 프로세스가 요구하는 자원의 양이라고 합시다. 이전 예시에서는 n을 주어진 함수를 계산할 숫자로 간주했지만, 다른 가능성도 있습니다. 예를 들어, 숫자의 제곱근에 대한 근사치를 계산하는 것이 목표라면, 필요한 자릿수 정확도를 n으로 간주할 수 있습니다. 행렬 곱셈의 경우 행렬의 행 수를 n으로 간주할 수 있습니다. 일반적으로 주어진 프로세스를 분석하는 데 바람직할 문제의 여러 속성이 있습니다. 마찬가지로 $R(n)$은 사용된 내부 저장 레지스터의 수, 수행된 기본 기계 연산의 수 등을 측정할 수 있습니다. 한 번에 고정된 수의 연산만 수행하는 컴퓨터에서는 필요한 시간이 수행된 기본 기계 연산 수에 비례할 것입니다.

우리는 $R(n)$이 $\Theta(f(n))$의 성장 차수를 가진다고 말합니다. R(n)=Theta(f(n)) (발음은 "f(n)의 세타")로 표기하며, 이는 n에 독립적인 양의 상수 $k_{1}$과 $k_{2}$가 존재하여 충분히 큰 n 값에 대해 ${k_{1}f(n)} \leq {R(n)} \leq {k_{2}f(n)}$가 성립함을 의미합니다. (다시 말해, 큰 n에 대해 R(n) 값은 $k_{1}f(n)$과 k_2f(n) 사이에 끼여 있습니다.)

예를 들어, 1.2.1절 에 설명된 팩토리얼 계산을 위한 선형 재귀 프로세스에서 단계 수는 입력 n에 비례하여 증가합니다. 따라서 이 프로세스에 필요한 단계는 $\Theta(n)$으로 증가합니다. 우리는 또한 필요한 공간이 $\Theta(n)$으로 증가한다는 것을 보았습니다. 반복 팩토리얼의 경우, 단계 수는 여전히 $\Theta(n)$이지만 공간은 $\Theta(1)$입니다. 즉, 상수입니다.^[이러한 진술은 많은 단순화를 가리고 있습니다. 예를 들어, 프로세스 단계를 "기계 연산"으로 간주할 때, 우리는 곱셈을 수행하는 데 필요한 기계 연산 수가 곱해질 숫자의 크기와 무관하다는 가정을 하고 있는데, 이는 숫자가 충분히 크다면 거짓입니다. 공간 추정에도 유사한 사항이 적용됩니다. 프로세스의 설계 및 설명과 마찬가지로, 프로세스의 분석은 다양한 추상화 수준에서 수행될 수 있습니다.] 트리 재귀 피보나치 계산은 Theta(varphin) 단계와 Theta(n) 공간을 요구하며, 여기서 varphi는 1.2.2절 에서 설명된 황금 비율입니다.

성장 차수는 프로세스 동작에 대한 대략적인 설명만을 제공합니다. 예를 들어, n2 단계가 필요한 프로세스와 1000n2 단계가 필요한 프로세스, 그리고 3n2+10n+17 단계가 필요한 프로세스는 모두 $\Theta(n^{2})$의 성장 차수를 가집니다. 반면에 성장 차수는 문제의 크기를 변경함에 따라 프로세스의 동작이 어떻게 변할 것으로 예상할 수 있는지에 대한 유용한 지표를 제공합니다. Theta(n)(선형) 프로세스의 경우 크기를 두 배로 늘리면 사용되는 자원의 양도 대략 두 배가 됩니다. 지수 프로세스의 경우 문제 크기가 1씩 증가할 때마다 자원 사용량이 상수 계수로 곱해집니다. 1.2절 의 나머지 부분에서는 성장 차수가 로그적인 두 가지 알고리즘을 살펴볼 것입니다. 따라서 문제 크기를 두 배로 늘리면 자원 요구 사항이 일정한 양만큼 증가합니다.

**연습문제 1.14:** 1.2.2절 의 `count-change` 프로시저가 11센트를 거스름돈으로 만들 때 생성하는 프로세스를 나타내는 트리를 그리시오. 이 프로세스가 사용하는 공간 및 단계 수의 성장 차수(금액이 증가함에 따라)는 무엇입니까?

**연습문제 1.15:** 각도(라디안으로 지정됨)의 사인(sine)은 x가 충분히 작으면 sinxapproxx를 활용하고, 삼각 항등식

$${\sin x}\, = \,{3\sin\frac{x}{3}}\, - \,{4\sin^{3}\frac{x}{3}}$$

을 사용하여 sin의 인수의 크기를 줄여 계산할 수 있습니다. (이 연습을 위해 각도의 크기가 0.1 라디안보다 크지 않으면 "충분히 작다"고 간주됩니다.) 이러한 아이디어는 다음 프로시저에 통합되어 있습니다.

코드 스니펫

```
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
```

1. `(sine 12.15)`가 평가될 때 프로시저 `p`는 몇 번 적용됩니까?
    
2. `(sine a)`가 평가될 때 `sine` 프로시저가 생성하는 프로세스가 사용하는 공간 및 단계 수의 성장 차수(a의 함수로)는 무엇입니까?
    

## 1.2.4 지수 계산

주어진 숫자의 지수 계산 문제를 생각해 봅시다. 밑 b와 양의 정수 지수 n을 인수로 받아 $b^{n}$을 계산하는 프로시저를 원합니다. 이를 수행하는 한 가지 방법은 다음 재귀 정의를 이용하는 것입니다.

$$\begin{array}{l}
{b^{n}\, = \, b \cdot b^{n - 1},} \\
{b^{0}\, = \, 1,} \\
\end{array}$$

이는 다음 프로시저로 쉽게 변환됩니다.

코드 스니펫

```
(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
```

이것은 Theta(n) 단계와 Theta(n) 공간을 요구하는 선형 재귀 프로세스입니다. 팩토리얼과 마찬가지로, 동등한 선형 반복을 쉽게 공식화할 수 있습니다.

코드 스니펫

```
(define (expt b n)
  (expt-iter b n 1))

(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                 (- counter 1)
                 (* b product))))
```

이 버전은 Theta(n) 단계와 Theta(1) 공간을 요구합니다.

연속 제곱을 사용하여 더 적은 단계로 지수을 계산할 수 있습니다. 예를 들어, $b^{8}$을

$${b \cdot (b \cdot (b} \cdot {(b \cdot (b \cdot (b} \cdot {(b \cdot b)))))),}$$

으로 계산하는 대신, 세 번의 곱셈을 사용하여 계산할 수 있습니다.

$$\begin{array}{l}
{b^{2}\, = \, b \cdot b,} \\
{b^{4}\, = \, b^{2} \cdot b^{2},} \\
{b^{8}\, = \, b^{4} \cdot b^{4}.} \\
\end{array}$$

이 방법은 2의 거듭제곱인 지수에 대해 잘 작동합니다. 또한 다음 규칙을 사용하면 일반적으로 지수를 계산할 때 연속 제곱의 이점을 활용할 수 있습니다.

$$\begin{array}{ll}
{b^{n}\, = \,(b^{n/2})^{2}} & {\text{if}\; n\;\text{is\ even},} \\
{b^{n}\, = \, b \cdot b^{n - 1}} & {\text{if}\; n\;\text{is\ odd}.} \\
\end{array}$$

이 방법을 프로시저로 표현할 수 있습니다.

코드 스니펫

```
(define (fast-expt b n)
  (cond ((= n 0)
         1)
        ((even? n)
         (square (fast-expt b (/ n 2))))
        (else
         (* b (fast-expt b (- n 1))))))
```

정수가 짝수인지 테스트하는 술어는 기본 프로시저 `remainder`를 사용하여 다음과 같이 정의됩니다.

코드 스니펫

```
(define (even? n)
  (= (remainder n 2) 0))
```

`fast-expt`에 의해 진화된 프로세스는 공간과 단계 수 모두에서 n에 대해 로그적으로 증가합니다. 이를 확인하려면, `fast-expt`를 사용하여 $b^{2n}$을 계산하는 데 $b^{n}$을 계산하는 것보다 곱셈이 단 하나 더 필요하다는 점을 관찰하십시오. 따라서 계산할 수 있는 지수의 크기는 허용되는 새로운 곱셈마다 (대략) 두 배가 됩니다. 따라서 지수 n에 필요한 곱셈 수는 n의 밑이 2인 로그만큼 빠르게 증가합니다. 이 프로세스는 Theta(logn) 성장을 가집니다.^[더 정확하게는 필요한 곱셈 수는 n의 이진 표현에서 1의 개수에 2의 로그 값에서 1을 뺀 것과 같습니다. 이 총합은 항상 n의 2의 로그 값의 두 배 미만입니다. 차수 표기법 정의의 임의 상수 $k_{1}$과 $k_{2}$는 로그 프로세스의 경우 로그를 취하는 밑이 중요하지 않으므로 모든 그러한 프로세스는 $\Theta(\log n)$으로 설명됨을 의미합니다.]

Theta(logn) 성장과 Theta(n) 성장의 차이는 n이 커질수록 두드러집니다. 예를 들어, n=1000일 때 `fast-expt`는 14번의 곱셈만 필요합니다.^[왜 누가 숫자를 1000제곱하는 데 신경 쓸까 하고 궁금해할 수도 있습니다. 1.2.6절 을 참조하십시오.] 연속 제곱의 아이디어를 사용하여 로그 단계 수로 지수를 계산하는 반복 알고리즘을 고안할 수도 있습니다 (연습 1.16 참조). 비록 반복 알고리즘의 경우 흔히 그렇듯이 재귀 알고리즘만큼 간단하게 작성되지는 않습니다.^[이 반복 알고리즘은 고대부터 전해져 내려오는 것입니다. 기원전 200년 이전에 쓰여진 Pingala의 Chandah-sutra에서 그 사용 예시를 찾을 수 있습니다. Knuth 1981, 4.6.3절에서 이 지수 계산 방법 및 다른 방법들에 대한 자세한 논의와 분석을 참조하십시오.]

**연습문제 1.16:** 연속 제곱을 사용하고 `fast-expt`와 같이 로그 단계 수를 사용하는 반복 지수 계산 프로세스를 진화시키는 프로시저를 설계하시오. (힌트: ${(b^{n/2})^{2}} = {(b^{2})^{n/2}}$이라는 관찰을 사용하여 지수 n과 밑 b와 함께 추가 상태 변수 a를 유지하고, 상태 변환을 abn 곱이 상태 간에 변경되지 않도록 정의하시오. 프로세스 시작 시 a는 1로 간주하고, 답은 프로세스 끝에서 a의 값으로 주어집니다. 일반적으로 상태 간에 변경되지 않는 _불변량_을 정의하는 기술은 반복 알고리즘 설계를 생각하는 강력한 방법입니다.)

**연습문제 1.17:** 이 절의 지수 계산 알고리즘은 반복 곱셈을 통한 지수 계산에 기반합니다. 유사한 방식으로, 반복 덧셈을 통해 정수 곱셈을 수행할 수 있습니다. 다음 곱셈 프로시저는 (우리 언어가 곱셈이 아닌 덧셈만 할 수 있다고 가정) `expt` 프로시저와 유사합니다.

코드 스니펫

```
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
```

이 알고리즘은 `b`에 선형적인 단계 수를 필요로 합니다. 이제 덧셈과 함께, 정수를 두 배로 만드는 `double` 연산과 (짝수) 정수를 2로 나누는 `halve` 연산을 포함한다고 가정합시다. 이것들을 사용하여 `fast-expt`와 유사하게 로그 단계 수를 사용하는 곱셈 프로시저를 설계하시오.

**연습문제 1.18:** 연습 1.16 과 연습 1.17 의 결과를 사용하여, 덧셈, 두 배, 반으로 나누기를 통해 두 정수를 곱하고 로그 단계 수를 사용하는 반복 프로세스를 생성하는 프로시저를 고안하시오.^[이 알고리즘은 때때로 "러시아 농부 곱셈법"으로 알려져 있으며 고대부터 전해져 내려오는 것입니다. 그 사용 예시는 기원전 1700년경에 이집트 서기관 아흐모세(A'h-mose)가 작성한(그리고 훨씬 더 오래된 문서에서 복사된) 현존하는 가장 오래된 수학 문서 중 하나인 린드 파피루스에서 발견됩니다.]

**연습문제 1.19:** 피보나치 수를 로그 단계 수로 계산하는 영리한 알고리즘이 있습니다. 1.2.2절 의 `fib-iter` 프로세스에서 상태 변수 a와 b의 변환을 상기하십시오: aleftarrowa+b 및 bleftarrowa. 이 변환을 T라고 부르고, 1과 0으로 시작하여 T를 n번 반복 적용하면 쌍 $\text{Fib}(n + 1)$과 $\text{Fib}(n)$이 생성된다는 것을 관찰하십시오. 다시 말해, 피보나치 수는 쌍 (1, 0)에서 시작하여 변환 T의 n제곱인 $T^{n}$을 적용하여 생성됩니다. 이제 T_pq 변환 가족에서 p=0 및 q=1의 특수한 경우로 T를 고려하십시오. 여기서 $T_{pq}$는 쌍 $(a,b)$를 aleftarrowbq+aq+ap 및 $b\leftarrow{bp} + {aq}$에 따라 변환합니다. 이러한 변환 $T_{pq}$를 두 번 적용하면 동일한 형태의 단일 변환 $T_{p^{\prime}q^{\prime}}$을 사용하는 것과 동일한 효과를 가지며, p와 q의 항으로 $p^{\prime}!$와 $q^{\prime}!$를 계산함을 보이시오. 이것은 이러한 변환을 제곱하는 명시적인 방법을 제공하며, 따라서 `fast-expt` 프로시저에서와 같이 연속 제곱을 사용하여 $T^{n}$을 계산할 수 있습니다. 이 모든 것을 통합하여 다음 프로시저를 완성하시오. 이 프로시저는 로그 단계 수로 실행됩니다.^[이 연습은 Joe Stoy가 Kaldewaij 1990의 예시를 바탕으로 제안했습니다.]

코드 스니펫

```
(define (fib n)
  (fib-iter 1 0 0 1 n))

(define (fib-iter a b p q count)
  (cond ((= count 0)
         b)
        ((even? count)
         (fib-iter a
                   b
                   ⟨??⟩  ; compute p'
                   ⟨??⟩  ; compute q'
                   (/ count 2)))
        (else
         (fib-iter (+ (* b q)
                      (* a q)
                      (* a p))
                   (+ (* b p)
                      (* a q))
                   p
                   q
                   (- count 1)))))
```

## 1.2.5 최대 공약수

두 정수 a와 b의 최대 공약수(GCD)는 a와 b를 나머지 없이 나누는 가장 큰 정수로 정의됩니다. 예를 들어, 16과 28의 GCD는 4입니다. 2장 에서 유리수 산술을 구현하는 방법을 조사할 때, 유리수를 기약분수로 줄이기 위해 GCD를 계산할 수 있어야 합니다. (유리수를 기약분수로 줄이려면 분자와 분모를 GCD로 나누어야 합니다. 예를 들어, 16/28은 4/7로 줄어듭니다.) 두 정수의 GCD를 찾는 한 가지 방법은 인수 분해하여 공통 인수를 찾는 것이지만, 훨씬 더 효율적인 유명한 알고리즘이 있습니다.

이 알고리즘의 아이디어는 a를 b로 나누었을 때 나머지가 r이라면, a와 b의 공통 약수는 정확히 b와 r의 공통 약수와 같다는 관찰에 기반합니다. 따라서 우리는 방정식을 사용할 수 있습니다.

코드 스니펫

```
GCD(a,b) = GCD(b,r)
```

GCD를 계산하는 문제를 점점 더 작은 정수 쌍의 GCD를 계산하는 문제로 연속적으로 줄일 수 있습니다. 예를 들어,

코드 스니펫

```
GCD(206,40) = GCD(40,6)
            = GCD(6,4)
            = GCD(4,2)
            = GCD(2,0) = 2
```

는 GCD(206, 40)를 GCD(2, 0)로 줄이며, 이는 2입니다. 어떤 두 양의 정수로 시작하여 반복적인 감소를 수행하면 항상 두 번째 숫자가 0인 쌍이 결국 생성됨을 보일 수 있습니다. 그러면 GCD는 쌍의 다른 숫자입니다. GCD를 계산하는 이 방법을 _유클리드 알고리즘_이라고 합니다.^[유클리드 알고리즘은 유클리드의 『원론』(기원전 300년경, 7권)에 나오기 때문에 그렇게 불립니다. Knuth (1973)에 따르면, 알려진 가장 오래된 비자명 알고리즘으로 간주될 수 있습니다. 고대 이집트의 곱셈 방법(연습 1.18)은 분명히 더 오래되었지만, Knuth가 설명하듯이 유클리드 알고리즘은 일련의 예시가 아닌 일반적인 알고리즘으로 제시된 알려진 가장 오래된 것입니다.]

유클리드 알고리즘을 프로시저로 표현하는 것은 쉽습니다.

코드 스니펫

```
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
```

이것은 관련된 숫자의 로그에 따라 단계 수가 증가하는 반복 프로세스를 생성합니다.

유클리드 알고리즘에 필요한 단계 수가 로그적으로 증가한다는 사실은 피보나치 수와 흥미로운 관계를 가지고 있습니다.

> **라메의 정리:** 만약 유클리드 알고리즘이 어떤 쌍의 GCD를 계산하는 데 k 단계를 요구한다면, 해당 쌍의 더 작은 숫자는 k번째 피보나치 숫자보다 크거나 같아야 합니다.^[이 정리는 1845년 프랑스 수학자이자 공학자인 가브리엘 라메가 증명했습니다. 그는 주로 수리 물리학에 대한 기여로 알려져 있습니다. 이 정리를 증명하기 위해 우리는 유클리드 알고리즘이 k 단계에서 종료되는 쌍 (a_k,b_k) (여기서 a_kgeqb_k)를 고려합니다. 증명은 감소 과정에서 세 개의 연속적인 쌍 ${(a_{k + 1},b_{k + 1})}\rightarrow{(a_{k},b_{k})}\rightarrow{(a_{k - 1},b_{k - 1})}$이 있다면, $b_{k + 1} \geq b_{k} + b_{k - 1}$이 성립해야 한다는 주장에 기반합니다. 주장을 확인하기 위해, 감소 단계는 a_k−1=b_k, b_k−1= $a_{k}$를 $b_{k}$로 나눈 나머지 변환을 적용하여 정의됩니다. 두 번째 방정식은 a_k=qb_k+b_k−1 (어떤 양의 정수 q에 대해)임을 의미합니다. 그리고 q는 적어도 1이어야 하므로 $a_{k} = {qb_{k}} + b_{k - 1} \geq b_{k} + b_{k - 1}$입니다. 그러나 이전 감소 단계에서 우리는 $b_{k + 1} = a_{k}$를 가집니다. 따라서 $b_{k + 1} = a_{k} \geq b_{k} + b_{k - 1}$입니다. 이는 주장을 확인합니다. 이제 우리는 알고리즘이 종료되는 데 필요한 단계 수 k에 대한 귀납법으로 정리를 증명할 수 있습니다. 결과는 k=1일 때 참입니다. 이는 단순히 b가 최소한 textFib(1)=1보다 커야 함을 요구하기 때문입니다. 이제 결과가 k 이하의 모든 정수에 대해 참이라고 가정하고 k+1에 대한 결과를 확립합니다. 감소 과정에서 연속적인 쌍을 ${(a_{k + 1},b_{k + 1})}\rightarrow{(a_{k},b_{k})}\rightarrow{(a_{k - 1},b_{k - 1})}$이라고 합시다. 우리의 귀납 가설에 따라 우리는 b_k−1geqtextFib(k−1) 및 $b_{k} \geq {\text{Fib}(k)}$를 가집니다. 따라서 방금 증명한 주장과 피보나치 수의 정의를 함께 적용하면 $b_{k + 1} \geq b_{k} + b_{k - 1} \geq {\text{Fib}(k)} + {\text{Fib}(k - 1)} = {\text{Fib}(k + 1)}$이 되며, 이는 라메의 정리 증명을 완료합니다.]

이 정리를 사용하여 유클리드 알고리즘의 성장 차수를 추정할 수 있습니다. n을 프로시저에 대한 두 입력 중 더 작은 값이라고 합시다. 프로세스가 k 단계를 수행하면 $n \geq {\text{Fib}(k)} \approx {\varphi^{k}/\sqrt{5}}$여야 합니다. 따라서 단계 수 k는 n의 (밑이 varphi인) 로그에 따라 증가합니다. 그러므로 성장 차수는 $\Theta(\log n)$입니다.

**연습문제 1.20:** 프로시저가 생성하는 프로세스는 물론 인터프리터가 사용하는 규칙에 따라 달라집니다. 예를 들어, 위에 주어진 반복 `gcd` 프로시저를 고려하십시오. 1.1.5절 에서 논의된 바와 같이, 정규 순서 평가를 사용하여 이 프로시저를 해석한다고 가정해 봅시다. (`if`에 대한 정규 순서 평가 규칙은 연습 1.5 에 설명되어 있습니다.) 대치 방법(정규 순서의 경우)을 사용하여 `(gcd 206 40)`을 평가할 때 생성되는 프로세스를 설명하고, 실제로 수행되는 `remainder` 연산을 표시하시오. `(gcd 206 40)`의 정규 순서 평가에서 실제로 수행되는 `remainder` 연산은 몇 개입니까? 적용 순서 평가에서는 몇 개입니까?

## 1.2.6 예시: 소수성 검사

이 섹션에서는 정수 n의 소수성을 확인하는 두 가지 방법을 설명합니다. 하나는 $\Theta(\sqrt{n})$의 성장 차수를 가지며, 다른 하나는 $\Theta(\log n)$의 성장 차수를 가지는 "확률적" 알고리즘입니다. 이 섹션 끝의 연습문제는 이러한 알고리즘을 기반으로 한 프로그래밍 프로젝트를 제안합니다.

### 약수 찾기

고대부터 수학자들은 소수에 관한 문제에 매료되어 왔으며, 많은 사람들이 숫자가 소수인지 테스트하는 방법을 결정하는 문제에 대해 연구했습니다. 숫자가 소수인지 테스트하는 한 가지 방법은 숫자의 약수를 찾는 것입니다. 다음 프로그램은 주어진 숫자 n의 가장 작은 정수 약수(1보다 큰)를 찾습니다. 이는 2부터 시작하여 연속적인 정수로 n이 나누어지는지 테스트하는 간단한 방법으로 수행합니다.

코드 스니펫

```
(define (smallest-divisor n)
  (find-divisor n 2))

(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n)
         n)
        ((divides? test-divisor n)
         test-divisor)
        (else (find-divisor
               n
               (+ test-divisor 1)))))

(define (divides? a b)
  (= (remainder b a) 0))
```

숫자가 소수인지 다음과 같이 테스트할 수 있습니다. n은 n이 자신의 가장 작은 약수인 경우에만 소수입니다.

코드 스니펫

```
(define (prime? n)
  (= n (smallest-divisor n)))
```

`find-divisor`의 종료 테스트는 n이 소수가 아니라면 $\sqrt{n}$보다 작거나 같은 약수를 가져야 한다는 사실에 기반합니다.^[만약 d가 n의 약수라면, n,/,d도 약수입니다. 하지만 d와 n,/,d 둘 다 $\sqrt{n}$보다 클 수는 없습니다.] 이는 알고리즘이 1과 sqrtn 사이의 약수만 테스트하면 된다는 것을 의미합니다. 결과적으로 n이 소수임을 식별하는 데 필요한 단계 수는 $\Theta(\sqrt{n})$의 성장 차수를 가질 것입니다.

### 페르마 테스트

Theta(logn) 소수성 테스트는 페르마의 소정리라고 알려진 수론 결과에 기반합니다.^[피에르 드 페르마 (1601-1665)는 현대 정수론의 창시자로 여겨집니다. 그는 많은 중요한 정수론적 결과를 얻었지만, 일반적으로 자신의 증명을 제공하지 않고 결과만을 발표했습니다. 페르마의 소정리는 1640년에 쓴 편지에 언급되었습니다. 최초로 출판된 증명은 1736년 오일러에 의해 제시되었고 (그보다 이전에 라이프니츠의 미출판 원고에서 동일한 증명이 발견되었습니다). 페르마의 가장 유명한 결과인 페르마의 마지막 정리는 1637년 자신의 『산술(Arithmetic)』(3세기 그리스 수학자 디오판토스 저) 사본에 "나는 정말 놀라운 증명을 발견했지만, 이 여백은 그것을 담기에는 너무 작다."라는 주석과 함께 갈겨쓰였습니다. 페르마의 마지막 정리에 대한 증명을 찾는 것은 정수론에서 가장 유명한 도전 중 하나가 되었고, 완전한 해결책은 1995년에 프린스턴 대학교의 앤드루 와일즈에 의해 제시되었습니다.]

> **페르마의 소정리:** n이 소수이고 a가 n보다 작은 임의의 양의 정수이면, a의 n제곱은 n을 법으로 a와 합동입니다.

(두 수는 n으로 나누었을 때 같은 나머지를 가지면 n을 법으로 _합동_이라고 합니다. 숫자 a를 n으로 나누었을 때의 나머지는 또한 a _모듈로_ n 또는 단순히 a _모듈로_ n으로도 불립니다.)

만약 n이 소수가 아니라면, 일반적으로 $a \< n$인 대부분의 숫자는 위 관계를 만족하지 않을 것입니다. 이는 소수성 테스트를 위한 다음 알고리즘으로 이어집니다. 숫자 n이 주어지면, n보다 작은 임의의 숫자 a를 선택하고 $a^{n}$을 n으로 나눈 나머지를 계산합니다. 만약 결과가 a와 같지 않으면, n은 확실히 소수가 아닙니다. 만약 a라면, n이 소수일 가능성이 높습니다. 이제 다른 임의의 숫자 a를 선택하고 동일한 방법으로 테스트합니다. 만약 그것도 방정식을 만족한다면, n이 소수라는 확신을 더욱 높일 수 있습니다. 점점 더 많은 a 값을 시도함으로써 결과에 대한 확신을 높일 수 있습니다. 이 알고리즘은 페르마 테스트라고 알려져 있습니다.

페르마 테스트를 구현하려면, 숫자의 지수를 다른 숫자를 법으로 하여 계산하는 프로시저가 필요합니다.

코드 스니펫

```
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (square (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base (expmod base (- exp 1) m))
          m))))
```

이것은 1.2.4절 의 `fast-expt` 프로시저와 매우 유사합니다. 연속 제곱을 사용하므로 단계 수가 지수와 함께 로그적으로 증가합니다.^[지수 e가 1보다 큰 경우의 감소 단계는 임의의 정수 x, y, m에 대해 x와 y를 각각 m으로 나눈 나머지를 따로 계산하고, 이들을 곱한 다음 그 결과를 m으로 나눈 나머지를 취함으로써 x 곱하기 y를 m으로 나눈 나머지를 찾을 수 있다는 사실에 기반합니다. 예를 들어, e가 짝수인 경우, $b^{e/2}$를 m으로 나눈 나머지를 계산하고, 이를 제곱한 다음 그 결과를 m으로 나눈 나머지를 취합니다. 이 기술은 m보다 훨씬 큰 숫자를 다룰 필요 없이 계산을 수행할 수 있다는 점에서 유용합니다. (연습 1.25 와 비교해보십시오.)]

페르마 테스트는 1과 n−1 사이의 임의의 숫자 a를 선택하고, a의 n 제곱을 n으로 나눈 나머지가 a와 같은지 확인하여 수행됩니다. 임의의 숫자 a는 Scheme에 원시 함수로 포함되어 있다고 가정하는 `random` 프로시저를 사용하여 선택됩니다. `random`은 정수 입력보다 작은 음이 아닌 정수를 반환합니다. 따라서 1과 n−1 사이의 임의의 숫자를 얻으려면 `random`을 n−1을 입력으로 호출하고 결과에 1을 더합니다.

코드 스니펫

```
(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
```

다음 프로시저는 매개변수로 지정된 횟수만큼 테스트를 실행합니다. 테스트가 매번 성공하면 true 값을 반환하고, 그렇지 않으면 false 값을 반환합니다.

코드 스니펫

```
(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n)
         (fast-prime? n (- times 1)))
        (else false)))
```

### 확률적 방법

페르마 테스트는 대부분의 익숙한 알고리즘과는 성격이 다릅니다. 익숙한 알고리즘에서는 정확성이 보장되는 답을 계산합니다. 여기서는 얻은 답이 _아마도_ 정확할 뿐입니다. 더 정확히 말하면, n이 페르마 테스트에서 실패하면 n이 소수가 아니라는 것을 확실히 알 수 있습니다. 그러나 n이 테스트를 통과했다는 사실은 매우 강력한 지표이지만, n이 소수임을 보장하지는 않습니다. 우리가 말하고 싶은 것은 어떤 숫자 n에 대해 테스트를 충분히 많이 수행하고 n이 항상 테스트를 통과한다는 것을 발견하면 소수성 테스트의 오류 확률을 원하는 만큼 작게 만들 수 있다는 것입니다.

안타깝게도 이 주장은 완전히 정확하지 않습니다. 페르마 테스트를 속이는 숫자는 존재합니다. 즉, 소수가 아니면서도 $a \< n$인 모든 정수 a에 대해 $a^{n}$이 n을 법으로 a와 합동인 속성을 가진 숫자 n이 존재합니다. 이러한 숫자는 매우 드물기 때문에 페르마 테스트는 실제로 매우 신뢰할 수 있습니다.^[페르마 테스트를 속이는 숫자를 _카마이클 수_라고 부르며, 매우 드물다는 것 외에는 거의 알려진 바가 없습니다. 100,000,000 미만에는 255개의 카마이클 수가 있습니다. 가장 작은 몇 개는 561, 1105, 1729, 2465, 2821, 6601입니다. 무작위로 선택된 매우 큰 숫자의 소수성을 테스트할 때, 페르마 테스트를 속이는 값을 우연히 발견할 확률은 우주 방사선이 컴퓨터를 오작동시켜 "올바른" 알고리즘을 수행하는 데 오류를 일으킬 확률보다 낮습니다. 첫 번째 이유로 알고리즘이 부적절하다고 생각하지만 두 번째 이유로는 그렇지 않다고 생각하는 것은 수학과 공학의 차이를 보여줍니다.]

페르마 테스트를 속일 수 없는 변형이 있습니다. 이 테스트에서는 페르마 방법과 마찬가지로 n보다 작은 임의의 정수 a를 선택하고 n과 a에 따라 달라지는 특정 조건을 확인하여 정수 n의 소수성을 테스트합니다. (이러한 테스트의 예는 연습 1.28 참조). 반면에 페르마 테스트와 대조적으로, n이 소수가 아닌 홀수라면 n보다 작은 정수 a의 절반 이상에서 조건이 성립하지 않는다는 것을 증명할 수 있습니다. 따라서 n이 a의 무작위 선택에 대해 테스트를 통과하면 n이 소수일 확률이 50%를 넘습니다. n이 a의 두 가지 무작위 선택에 대해 테스트를 통과하면 n이 소수일 확률이 3/4를 넘습니다. 점점 더 많은 무작위 a 값을 사용하여 테스트를 실행하면 오류 확률을 원하는 만큼 작게 만들 수 있습니다.

오류 가능성이 임의로 작아질 수 있음을 증명할 수 있는 테스트의 존재는 이러한 유형의 알고리즘에 대한 관심을 불러일으켰으며, 이는 _확률적 알고리즘_으로 알려지게 되었습니다. 이 분야에서는 많은 연구 활동이 이루어지고 있으며, 확률적 알고리즘은 많은 분야에 성공적으로 적용되었습니다.^[확률적 소수성 테스트의 가장 눈에 띄는 응용 분야 중 하나는 암호학입니다. 임의의 200자리 숫자를 인수분해하는 것은 현재 계산적으로 불가능하지만, 페르마 테스트를 사용하면 몇 초 만에 그러한 숫자의 소수성을 확인할 수 있습니다. 이 사실은 Rivest et al. (1977)이 제안한 "깨지지 않는 코드"를 구성하는 기술의 기반이 됩니다. 그 결과인 _RSA 알고리즘_은 전자 통신의 보안을 강화하는 데 널리 사용되는 기술이 되었습니다. 이와 관련된 발전으로 인해, 한때 "순수" 수학의 주제로 자체적인 목적을 위해서만 연구되어야 하는 것으로 여겨졌던 소수 연구는 이제 암호학, 전자 자금 이체 및 정보 검색에 중요한 실용적인 응용 분야를 가지게 되었습니다.]

**연습문제 1.21:** `smallest-divisor` 프로시저를 사용하여 다음 각 숫자의 가장 작은 약수를 찾으시오: 199, 1999, 19999.

**연습문제 1.22:** 대부분의 Lisp 구현에는 시스템이 실행된 시간(예: 마이크로초 단위)을 지정하는 정수를 반환하는 `runtime`이라는 기본 요소가 포함되어 있습니다. 다음 `timed-prime-test` 프로시저는 정수 n과 함께 호출되면 n을 출력하고 n이 소수인지 확인합니다. n이 소수이면 프로시저는 별표 세 개와 함께 테스트를 수행하는 데 사용된 시간을 출력합니다.

코드 스니펫

```
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
```

코드 스니펫

```
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime)
                       start-time))))
```

코드 스니펫

```
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
```

이 프로시저를 사용하여 지정된 범위에서 연속적인 홀수의 소수성을 확인하는 `search-for-primes` 프로시저를 작성하시오. 당신의 프로시저를 사용하여 1000보다 큰 가장 작은 소수 세 개; 10,000보다 큰 가장 작은 소수 세 개; 100,000보다 큰 가장 작은 소수 세 개; 1,000,000보다 큰 가장 작은 소수 세 개를 찾으시오. 각 소수를 테스트하는 데 걸리는 시간을 기록하시오. 테스트 알고리즘이 $\Theta(\sqrt{n})$의 성장 차수를 가지므로, 10,000 주변의 소수를 테스트하는 데 1000 주변의 소수를 테스트하는 것보다 약 $\sqrt{10}$배 더 오래 걸릴 것으로 예상해야 합니다. 당신의 시간 데이터는 이것을 뒷받침합니까? 100,000과 1,000,000 데이터는 Theta(sqrtn) 예측을 얼마나 잘 지지합니까? 당신의 결과는 당신의 기계에서 프로그램이 계산에 필요한 단계 수에 비례하는 시간으로 실행된다는 개념과 일치합니까?

**연습문제 1.23:** 이 절의 시작 부분에 제시된 `smallest-divisor` 프로시저는 불필요한 테스트를 많이 수행합니다. 숫자가 2로 나누어지는지 확인한 후에는 더 큰 짝수로 나누어지는지 확인할 필요가 없습니다. 이는 `test-divisor`에 사용되는 값이 2, 3, 4, 5, 6, …이 아니라 2, 3, 5, 7, 9, …여야 한다는 것을 시사합니다. 이 변경 사항을 구현하려면 입력이 2이면 3을 반환하고 그렇지 않으면 입력에 2를 더한 값을 반환하는 `next` 프로시저를 정의하시오. `smallest-divisor` 프로시저를 수정하여 `(+ test-divisor 1)` 대신 `(next test-divisor)`를 사용하시오. 이 수정된 `smallest-divisor` 버전이 통합된 `timed-prime-test`를 사용하여 연습 1.22 에서 찾은 12개 소수 각각에 대해 테스트를 실행하시오. 이 수정은 테스트 단계를 절반으로 줄이므로 약 두 배 빠르게 실행될 것으로 예상해야 합니다. 이러한 예상은 확인되었습니까? 그렇지 않다면 두 알고리즘의 속도 비율은 얼마이며, 2와 다른 이유를 어떻게 설명할 수 있습니까?

**연습문제 1.24:** 연습 1.22 의 `timed-prime-test` 프로시저를 `fast-prime?` (페르마 방법)를 사용하도록 수정하고, 해당 연습에서 찾은 12개의 소수 각각을 테스트하시오. 페르마 테스트가 Theta(logn) 성장을 가지므로, 1,000,000 근처의 소수를 테스트하는 데 걸리는 시간이 1000 근처의 소수를 테스트하는 데 걸리는 시간과 어떻게 비교될 것이라고 예상합니까? 당신의 데이터는 이것을 뒷받침합니까? 발견한 불일치를 설명할 수 있습니까?

**연습문제 1.25:** 알리사 P. 해커는 `expmod`를 작성하는 데 많은 추가 작업을 했다고 불평합니다. 결국 그녀는 이미 지수를 계산하는 방법을 알고 있으므로 단순히 다음과 같이 작성할 수 있었다고 말합니다.

코드 스니펫

```
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
```

그녀가 옳습니까? 이 프로시저가 빠른 소수 테스트기로서도 잘 작동할까요? 설명하십시오.

**연습문제 1.26:** 루이스 리즈너는 연습 1.24 를 수행하는 데 큰 어려움을 겪고 있습니다. 그의 `fast-prime?` 테스트는 `prime?` 테스트보다 느리게 실행되는 것 같습니다. 루이스는 친구 에바 루 아터에게 도움을 요청합니다. 그들이 루이스의 코드를 검토했을 때, 그는 `expmod` 프로시저를 `square`를 호출하는 대신 명시적인 곱셈을 사용하도록 다시 작성했음을 발견합니다.

코드 스니펫

```
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (* (expmod base (/ exp 2) m)
             (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base
             (expmod base (- exp 1) m))
          m))))
```

루이스는 "무슨 차이가 있을지 모르겠어요."라고 말합니다. 에바는 "나는 알아요."라고 말합니다. "프로시저를 그렇게 작성함으로써 당신은 Theta(logn) 프로세스를 Theta(n) 프로세스로 변환했습니다." 설명하시오.

**연습문제 1.27:** 각주 47 에 나열된 카마이클 수가 실제로 페르마 테스트를 속인다는 것을 증명하시오. 즉, 정수 n을 받아 $a \< n$인 모든 a에 대해 $a^{n}$이 n을 법으로 a와 합동인지 테스트하는 프로시저를 작성하고, 주어진 카마이클 수에 대해 당신의 프로시저를 시도하시오.

**연습문제 1.28:** 페르마 테스트를 속일 수 없는 변형 중 하나를 _밀러-라빈 테스트_라고 합니다 ([Miller 1976]; [Rabin 1980]). 이 테스트는 페르마 소정리의 다른 형태에서 시작하는데, 이는 n이 소수이고 a가 n보다 작은 임의의 양의 정수이면, a를 $(n - 1)$승한 값이 n을 법으로 1과 합동이라는 것입니다. 밀러-라빈 테스트를 통해 숫자 n의 소수성을 테스트하려면, n보다 작은 임의의 숫자 a를 선택하고 `expmod` 프로시저를 사용하여 a를 $(n - 1)$승한 값을 n을 법으로 계산합니다. 그러나 `expmod`에서 제곱 단계를 수행할 때마다 "1의 비자명 제곱근 모듈로 n"을 발견했는지 확인합니다. 즉, 1 또는 n−1이 아닌 숫자 중 제곱이 n을 법으로 1과 같은 숫자를 말합니다. 이러한 비자명 제곱근이 존재하면 n이 소수가 아님을 증명할 수 있습니다. 또한 n이 소수가 아닌 홀수라면, n보다 작은 a의 절반 이상에 대해 이런 방식으로 $a^{n - 1}$을 계산하면 1의 비자명 제곱근 모듈로 n이 드러난다는 것을 증명할 수 있습니다. (이것이 밀러-라빈 테스트가 속지 않는 이유입니다.) `expmod` 프로시저를 수정하여 1의 비자명 제곱근을 발견하면 신호를 보내도록 하고, 이를 사용하여 `fermat-test`와 유사한 프로시저로 밀러-라빈 테스트를 구현하시오. 다양한 알려진 소수 및 비소수를 테스트하여 당신의 프로시저를 확인하시오. 힌트: `expmod`가 신호를 보내도록 하는 한 가지 편리한 방법은 0을 반환하도록 하는 것입니다.